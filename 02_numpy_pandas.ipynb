{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 2 - Numpy y pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Objetivos**\n",
    "\n",
    "* Prácticar Álgebra Lineal con `numpy`\n",
    "\n",
    "* Manejar datos tabulares con `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El *stack* científico con Python: `scipy`\n",
    "Librerías principales de datos en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NumPy: Paquete base de arrays/matrices N-dimensionales.\n",
    "\n",
    "* SciPy: Librería fundamental para computación científica.\n",
    "\n",
    "* IPython: Consola mejorada interactiva.\n",
    "\n",
    "* Pandas: Estructuras de datos y análisis.\n",
    "\n",
    "* Sympy: Matemática simbólica.\n",
    "\n",
    "* Matplotlib: Visualización 2D. Sirve para hacer representaciones gráficas de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 `matplotlib`  \n",
    "\n",
    "![Matplotlib](img/matplotlib.png)\n",
    "\n",
    "Matplotlib es una biblioteca que permite crear visualizaciones estáticas, animados e interactivas en Python. \n",
    "\n",
    "* Crear gráficos de calidad.\n",
    "* Hacer figuras interactivas que pueden ampliarse, desplazarse, actualizarse.\n",
    "* Personaliza el estilo visual y el diseño de los gráficos.\n",
    "* Exportar a muchos formatos de archivo.\n",
    "* Incrustar en JupyterLab e interfaces gráficas de usuario.\n",
    "\n",
    "Tutoriales de uso: https://matplotlib.org/stable/tutorials/index.html  \n",
    "\n",
    "Ejemplos de utilización: https://matplotlib.org/stable/plot_types/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 `numpy`\n",
    "![Numpy](img/numpy.png)\n",
    "\n",
    "Paquete base de matrices N-dimensionales.  \n",
    "\n",
    "Podemos utilizarlo para realizar operaciones con arrays. \n",
    "\n",
    "Sus arrays son tipados y pueden tener cualquier forma y dimensión que queramos.  \n",
    "\n",
    "Hay una serie de funciones para crear matrices especiales.\n",
    "\n",
    "Una ventaja central de numpy sobre las listas regulares de python, aparte de las muchas funciones de conveniencia, es la velocidad.  \n",
    "\n",
    "Y arrays de variables aleatorias.\n",
    "\n",
    "Página de numpy: https://numpy.org  \n",
    "\n",
    "API: https://numpy.org/doc/stable/reference/index.html#reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 2.1**\n",
    "\n",
    "Crea una muestra aleatoria de puntos que sigan la ecuación $Y = AX + B$, donde $A = 2.5$ y $B = 20$.\n",
    "\n",
    "Ahora, represéntala como una nube de puntos o como una recta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hacemos los imports de las librerias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2.5\n",
    "b = 20\n",
    "# Aquí se define el array de 1000 elementos\n",
    "x = np.arange(1000)\n",
    "\n",
    "y = a*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representamos la recta asociada a la función lineal definida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representamos la recta como una nube de puntos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 2.2**\n",
    "\n",
    "Crea una muestra aleatoria de puntos que sigan la ecuación $Y = AX + B$, donde $A = 5$ y $B = 500$.\n",
    "\n",
    "Ahora, represéntala como una nube de puntos y como una recta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aquí tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 2.3**\n",
    "\n",
    "Representa la función logística, o sigmoidea, entre -20 y 20 y represeéntala gáficamente. Recuerda que su fórmula es:\n",
    "\n",
    "$$\\displaystyle S(x)={\\frac {1}{1+e^{-x}}}={\\frac {e^{x}}{e^{x}+1}}$$\n",
    "\n",
    "*Sugerencia*: necesitarás una X y una Y para representarlas. La X debería ir entre -20 y 20.\n",
    "\n",
    "*Sugerencia*: echa un vistazo a la función np.exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aquí tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Índices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1.1 Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La notación para realizar slices en un array de Numpy es similara a las listas. Se utilizan los corchetes y los : para poder seleccionar el rango de los elementos que queremos obtener del array original.  \n",
    "\n",
    "* `a[m:n]`  Este slide seleccionaría los elementos que en el índice comience en m y termine en n-1.  \n",
    "* `a[:]`  Este slide seleccionaría todos los elementos del array. \n",
    "* `a[0:-1]` Este slide seleccionaría todos los elementos del array menos el último. \n",
    "* `a[:n]`  Este slide seleccionaría los elementos que en el índice comience en 0 y termine en n-1.  \n",
    "* `a[m:]`  Este slide seleccionaría los elementos que en el índice comience en m y termine en el último elemento del array.  \n",
    "* `a[m:-1]`  Este slide seleccionaría los elementos que en el índice comience en m y termine en el último elemento del array menos 1.  \n",
    "* `a[m:n:k]`  Este slide seleccionaría los elementos comprendidos entre m y n-1, con un incremento de k. \n",
    "* `a[::-1]`  Este slide seleccionaría los elementos del array en orden inverso. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0, 10)\n",
    "\n",
    "print('a=', a)\n",
    "print('a[2:5]=', a[2:5])\n",
    "print('a[:]=', a[:])\n",
    "print('a[0:-1]=', a[0:-1])\n",
    "print('a[0:6]=', a[0:6])\n",
    "print('a[7:]=', a[7:])\n",
    "print('a[5:-1]=', a[5:-1])\n",
    "print('a[0:5:2]=', a[0:5:2])\n",
    "print('a[::-1]=', a[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1.2 Slicing en arrays multidimensionales\n",
    "\n",
    "La forma de realizar slice en arrays multidimensionales es similar a la forma en que se hace para arrays unidimensionales. Es necesario aplicar el slice en los indices donde se quiera aplicar la operación de slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo en este array bidimensional los indices se representan de la siguiente manera:   \n",
    "  \n",
    "`a[filas, columnas]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[0:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[1:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Objeto Mutable  \n",
    "\n",
    "Los objetos array de numpy son mutable. Es necesario tener en cuenta esto si se hacen copias de objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.ones(10)\n",
    "arr2 = arr1\n",
    "print(arr1)\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 *= 2\n",
    "print(arr1)\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La copia se puede hacer, entre otras de 2 formas:\n",
    "\n",
    "* Haciendo que la variable no apunte al mismo objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.ones(10)\n",
    "arr2 = arr1\n",
    "print(arr1)\n",
    "print(arr2)\n",
    "\n",
    "print(\"Modificamos el array\")\n",
    "arr2 = arr2 *2\n",
    "print(arr1)\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Usando el método copy de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.ones(10)\n",
    "arr2 = arr1.copy()\n",
    "print(arr1)\n",
    "print(arr2)\n",
    "print(\"Modificamos el array\")\n",
    "arr2 *= 2\n",
    "print(arr1)\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Operaciones *element wise*\n",
    "\n",
    "Son operaciones que se realizan sobre cada elemento del array de forma individual.\n",
    "\n",
    "`np.add(), np.subtract(), np.multiply(), np.divide()`|Suma, resta, multiplicación y división.\n",
    "`np.power()`|Potencia. El elemento del primer array se eleva al elemento del segundo array.\n",
    "`np.remainder()`|Resto de la división.\n",
    "`np.reciprocal()`|Número recíproco (1/n)\n",
    "`np.sign(), np.abs()`|Signo y valor absoluto.\n",
    "`np.floor(), np.ceil()`|Redondea a la baja o al alza al siguiente número entero.\n",
    "`np.round()`|Redondea un úmero a los decimales pasados. Por defecto 0 decimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.array([[10, 20, 30], [40, 50, 60]])\n",
    "array2 = np.array([[2, 3, 4], [4, 6, 8]])\n",
    "array3 = np.array([[-2, 3.5, -4], [4.05, -6, 8]])\n",
    " \n",
    "print(np.add(array1, array2))\n",
    "print(\"-\" * 40)\n",
    " \n",
    "print(np.power(array1, array2))\n",
    "print(\"-\" * 40)\n",
    " \n",
    "print(np.remainder((array2), 5))\n",
    "print(\"-\" * 40)\n",
    " \n",
    "print(np.reciprocal(array3))\n",
    "print(\"-\" * 40)\n",
    " \n",
    "print(np.sign(array3))\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(np.abs(array3))\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(np.floor(array3))\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(np.ceil(array3))\n",
    "print(\"-\" * 40)\n",
    " \n",
    "print(np.round(array3,1))\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Operaciones matriciales\n",
    "\n",
    "Operaciones con matrices: \n",
    "https://economipedia.com/definiciones/operaciones-con-matrices.html#:~:text=Las%20operaciones%20con%20matrices%20son%20la%20suma%2C%20la,n%C3%BAmeros%20reales%20mediante%20coordenadas%20reflejadas%20en%20los%20sub%C3%ADndices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 `ndarray` vs `matrix`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Numpy matrix son matrices estrictamente bidimensionales mientras los objetos ndarray pueden ser multidimensionales.\n",
    "* Los objetos matrix son subclases de los objetos de tipo ndarray por lo que heredan todos los atributos y métodos de los objetos de tipo ndarray.\n",
    "* La ventaja principal de los objetos de tipo matrix es que tiene implementado el producto de matrices.\n",
    "* Ámbos tipos de objeto tienen implementado el método .T que devuelve la transpuesta del objato, pero los objetos de tipo matrix además tienen implementados méto .H que devuelve el conjugado del transpuesto y el método .I que devuelve la matriz inversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Álgebra Lineal con numpy\n",
    "\n",
    "http://docs.scipy.org/doc/numpy-1.10.0/reference/routines.linalg.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2.4\n",
    "\n",
    "En una granja de pollos y conejos hay 35 cabezas y 94 patas. \n",
    "\n",
    "¿Cuántos pollos y cuántos conejos tenemos?\n",
    "\n",
    "Remember:\n",
    "\n",
    "$$A \\cdot X = B$$\n",
    "\n",
    "$$A^{-1} \\cdot A \\cdot X = I \\cdot X = A^{-1} \\cdot B$$\n",
    "\n",
    "$$X = A^{-1} \\cdot B$$\n",
    "\n",
    "\\* <font size=\"2\">El lenguaje que he utilizado para representar esta fórmula es [$\\LaTeX$](https://www.latex-project.org/). Se utiliza para maquetar todo tipo de cosas, desde cvs a artículos científicos o libros. Puedes encontrar una introducción rápida [aquí](https://www.cs.princeton.edu/courses/archive/spr10/cos433/Latex/latex-guide.pdf). Casi todo lo que necesitas saber para escribir ecuaciones en el cuaderno está en las páginas 4,5 y 6 de ese pdf. </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistema de ecuaciones:\n",
    "\n",
    "35 = p + c  cabezas\n",
    "94 = 2*p + 4*c patas\n",
    "\n",
    "Pensando en forma matricial:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$B=\\left[\\begin{array}{c} 35 \\\\ 94\\end{array}\\right]$$\n",
    "$$A=\\left[\\begin{array}{c} 1 && 2 \\\\ 1 && 4\\end{array}\\right]$$\n",
    "  \n",
    "$$A*X=B$$\n",
    "\n",
    "$$\\left[\\begin{array}{c} 1 && 2 \\\\ 1 && 4\\end{array}\\right]* X = \\left[\\begin{array}{c} 35 \\\\ 94\\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.matrix([[1,1],[2,4]])\n",
    "B = np.matrix([[35],[94]])\n",
    "X = A**(-1)*B\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.5\n",
    "\n",
    "Con 450 gramos de medicamento se fabricaron 60 pastillas de tres \n",
    "tipos. Grandes, medianas y pequeñas. Las pastillas grandes pesan 20 gramos, las \n",
    "medianas 10 gramos y las pequeñas 5 gramos. Si el total de pastillas grandes y \n",
    "medianas es la mitad del número de pastillas pequeñas,  \n",
    "¿cuántas se fabricaron de cada tipo?\n",
    "\n",
    "Remember:\n",
    "\n",
    "$$A \\cdot X = B$$\n",
    "\n",
    "$$A^{-1} \\cdot A \\cdot X = I \\cdot X = A^{-1} \\cdot B$$\n",
    "\n",
    "$$X = A^{-1} \\cdot B$$\n",
    "\n",
    "\\* <font size=\"2\">El lenguaje que he utilizado para representar esta fórmula es [$\\LaTeX$](https://www.latex-project.org/). Se utiliza para maquetar todo tipo de cosas, desde cvs a artículos científicos o libros. Puedes encontrar una introducción rápida [aquí](https://www.cs.princeton.edu/courses/archive/spr10/cos433/Latex/latex-guide.pdf). Casi todo lo que necesitas saber para escribir ecuaciones en el cuaderno está en las páginas 4,5 y 6 de ese pdf. </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistema de ecuaciones:\n",
    "\n",
    "x: Número de pastillas grandes.  \n",
    "y: Número de pastillas medianas.  \n",
    "z: Número de pastillas pequeñas.  \n",
    "\n",
    "60 = x + y + z  \n",
    "450 = 20x + 10y + 5z  \n",
    "x+y = 2*z --> 0 = x+y-2z\n",
    "\n",
    "Pensando en forma matricial:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$B=\\left[\\begin{array}{c} 60 \\\\ 450 \\\\ 0\\end{array}\\right]$$\n",
    "$$A=\\left[\\begin{array}{c} 1 && 1 && 1 \\\\ 20 && 10 && 5 \\\\ 1 && 1 && 2\\end{array}\\right]$$\n",
    "  \n",
    "$$A*X=B$$\n",
    "\n",
    "$$\\left[\\begin{array}{c} 1 && 1 && 1 \\\\ 20 && 10 && 5 \\\\ 1 && 1 && 2\\end{array}\\right]* X = \\left[\\begin{array}{c} 60 \\\\ 450 \\\\ 0\\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu respuesta aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solución es x=5, y=15, z=40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.7 Información de interes de como se usa numpy\n",
    "\n",
    "[Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do)\n",
    "\n",
    "[What is SciPy?](https://www.scipy.org/)\n",
    "\n",
    "[How can SciPy be fast if it is written in an interpreted language like Python?](https://scipy.org/faq/)\n",
    "\n",
    "[What is the difference between NumPy and SciPy?](https://scipy.org/faq/)\n",
    "\n",
    "[Linear Algebra using Numpy and SciPy](https://medium.com/nerd-for-tech/linear-algebra-using-numpy-and-scipy-390be43d1cb0#:~:text=Linear%20Algebra%20using%20NumPy%20and%20SciPy%201%20NumPy,the%20multiplicative%20inverse%20of%20a%20matrix%20M%C3%A1s%20elementos)\n",
    "\n",
    "[Linear Algebra for AI](https://github.com/fastai/numerical-linear-algebra)\n",
    "\n",
    "[Aprende numpy con Alf](https://aprendeconalf.es/docencia/python/manual/numpy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 `pandas`  \n",
    "![Alt text](img/pandas.png)  \n",
    "  \n",
    "La librería pandas (nombre derivado de panel data, término usado para referirse a conjuntos de datos estructurados multidimensionales) proporciona estructuras de datos y funciones de alto nivel que nos permiten trabajar con datos estructurados de manera muy cómoda. Estas estructuras y funciones son, normalmente, de las más usadas en análisis de datos.\n",
    "\n",
    "Los principales objetos ofrecidos por pandas son el dataframe, estructura tabular bidimensional y la serie, ambas basadas en el array multidimensional de NumPy. Aun cuando NumPy ofrece una muy conveniente y eficiente estructura para el almacenamiento de datos, el ndarray, éste presenta importantes limitaciones cuando, durante un análisis, se hace necesaria más flexibilidad a la hora de aplicar etiquetas a nuestros datos, gestionar valores inexistentes, realizar agrupaciones por etiquetas, etc., limitaciones que son resueltas por las estructuras de más alto nivel ofrecidas por pandas.\n",
    "\n",
    "Esta librería se importa habitualmente con el alias pd:\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "Para poder hacer uso de las estructuras ofrecidas por pandas o de cualquiera de las funciones o métodos que incluye, deberás importar previamente la librería con la instrucción anterior. Aunque en las capturas de pantalla incluidas en este tutorial no se muestre, la importación de pandas se realiza en la primera celda del notebook Jupyter:\n",
    "\n",
    "Importación de pandas y de NumPy\n",
    "Como se ha comentado, pandas se basa en la funcionalidad de NumPy, por lo que numerosas funciones de esta última librería son perfectamente aplicables a las series y a los dataframes. Para poder probarlas, también deberemos importar la función NumPy, tal y como se ve en la anterior imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np #Incluimos numpy porque luego lo necesitaremos a la hora de crear series y dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Introducción a las estructuras de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.1 Introducción a las series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las series son estructuras unidimensionales conteniendo un array de datos (de cualquier tipo soportado por NumPy) y un array de etiquetas que van asociadas a los datos, llamado índice (index en la literatura en inglés):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas = pd.Series(data=[15,12,21], index=[\"Ene\", \"Feb\", \"Mar\"])\n",
    "s_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los elementos de la serie pueden extraerse con el nombre de la serie y, entre corchetes, el índice (posición) del elemento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...o su etiqueta, si la tiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas[\"Ene\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las etiquetas que forman el índice no necesitan ser diferentes. Pueden ser de cualquier tipo (numérico, textos, tuplas...) siempre que sea posible aplicar la función hash sobre ellas.\n",
    "\n",
    "Es de destacar que el lazo entre una etiqueta y un valor se mantendrá salvo que lo modifiquemos explícitamente. Esto quiere decir que filtrar una serie o eliminar un elemento de la serie, por ejemplo, no va a modificar las etiquetas asignadas a cada valor.\n",
    "\n",
    "Otro comentario importante es al respecto de la inmutabilidad del índice de etiquetas: aun cuando es posible asignar a una serie un nuevo conjunto de etiquetas a través del atributo index, intentar modificar un único valor del index va a devolver un error.\n",
    "\n",
    "Al igual que ocurre con el array NumPy, una serie pandas solo puede contener datos de un mismo tipo. En la imagen anterior puede apreciarse el índice a la izquierda (\"Ene\", \"Feb\" y \"Mar\") y los datos a la derecha (15, 12 y 21). El tipo de la serie, accesible a través del atributo dtype, coincide con el tipo de los datos que contiene:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder a los objetos que contienen los índices y los valores a través de los atributos index y values de la serie, respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede apreciarse que el índice es de tipo \"objeto\".  \n",
    "\n",
    "La serie tiene, además, un atributo name, atributo que también encontramos en el índice. Una vez los hemos fijado, se muestran junto con la \n",
    "estructura al imprimir la serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas.name = \"Ventas 2023\"\n",
    "s_ventas.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los índices también tienen dicho atributo como se puede ver en la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas.index.name = \"Meses\"\n",
    "s_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsérvese cómo, en la celda anterior, tanto la serie como el índice se muestran con su nombre (\"Ventas 2023\" y \"Meses\", respectivamente).  \n",
    "  \n",
    "El atributo axes nos da acceso a una lista con los ejes de la serie (solo contiene un elemento al tratarse de una estructura unidimensional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas.axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El atributo shape nos devuelve el tamaño de la serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.2 Introducción a los DataFrames\n",
    "\n",
    "Los dataframes son estructuras tabulares de datos orientadas a columnas, con etiquetas tanto en filas como en columnas:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas = pd.DataFrame({\n",
    "                            \"Entradas\": [41, 32, 56, 18],\n",
    "                            \"Salidas\": [17, 54, 6, 78],\n",
    "                            \"Valoración\": [66, 5, 49, 66],\n",
    "                            \"Límite\": [\"No\", \"Si\", \"No\", \"No\"],\n",
    "                            \"Cambio\": [1.23, 1.16, -0.67, 0.77]\n",
    "                        },\n",
    "                            index = [\"Ene\", \"Feb\", \"Mar\", \"Abr\"]\n",
    "                        )\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque veremos en una sección posterior cómo crear dataframes con detalle, puede apreciarse en la celda anterior que hemos pasado al constructor pd.DataFrame un diccionario y una lista: las claves del diccionario serán los nombres de las columnas, sus valores, los valores de las columnas, y los valores de la lista se convertirán las etiquetas de filas.  \n",
    "\n",
    "Una columna solo puede contener un tipo de datos, pero cada columna del dataframe puede contener un tipo de datos diferente. Podemos acceder a los tipos de las columnas con el atributo dtypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las etiquetas de filas y de columnas -los índices- son accesibles a través de los atributos index y columns, respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`La nomenclatura usada por pandas puede resultar un tanto confusa en lo que se refiere a los índices: tanto la estructura que contiene las etiquetas de filas como la que contiene las etiquetas de columnas son objetos de tipo Index (\"índice\", en español), pero, como se ha comentado, el índice de filas se denomina también index (aunque en minúsculas), y el de columna, columns.`\n",
    "\n",
    "`Además, el nombre de \"indice\" se aplica normalmente a la referencia de un dato en una estructura según su posición. Por ejemplo, en la lista m = [\"a\", \"b\"], el índice del primer elemento es el número o valor que, añadido entre corchetes tras el nombre de la lista, nos permite acceder al elemento. Así, el índice del elemento \"a\" en la lista mencionada es 0, y el índice del elemento \"b\" es 1, lo que no es del todo coherente con el concepto de \"índice\" de una estructura pandas cuando lo especificamos explícitamente.`\n",
    "\n",
    "`Para evitar esta confusión, a lo largo de esta documentación hablaremos normalmente de \"índices\" (en plural) para referirnos a estas dos estructuras (de filas y columnas), de \"índice\" (en singular) para referirnos al índice de etiquetas del eje vertical, y de \"índice de columnas\" y de \"índice de filas\" siempre que sea necesario remarcar a cuál estamos refiriéndonos.`  \n",
    "\n",
    "El eje 0 es el correspondiente al índice de filas (eje vertical) y el eje 1 al índice de columnas (eje horizontal). Como puede verse en las celdas anteriores, ambos índices son de tipo \"objeto\" (ya se ha comentado que, concretamente, son objetos de tipo Index)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El atributo axes devuelve una lista con los ejes de la estructura (dos, al tratarse de una estructura bidimensional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que ocurría con las series, los índices de filas y columnas son inmutables. Esto significa que, aunque podemos asignar un nuevo conjunto de datos (etiquetas) a ambas estructuras (index o columns), intentar modificar un único valor devolverá un error.\n",
    "\n",
    "Tanto el índice de filas como el de columnas poseen el atributo name. Una vez fijado, se muestra al imprimir la estructura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.index.name = \"Meses\"\n",
    "df_ventas.columns.name = \"Métricas\"\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma semejante a como ocurría con las series, el atributo values de un dataframe nos permite acceder a los valores del dataframe, con formato array NumPy 2d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este array tendrá un tipo u otro en función de los tipos de las columnas del dataframe, acomodándose de forma que englobe a todos ellos.\n",
    "\n",
    "Y un dataframe también tiene un atributo shape que nos informa de su dimensionalidad y del número de elementos en cada dimensión. Podemos ver en la siguiente imagen que el dataframe ventas tiene 4 filas y 5 columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Creación de series y dataframes  \n",
    "\n",
    "Hay dos constructores principales para la creación de series y dataframes: `pd.Series` y `pd.DataFrames`, respectivamente. Estos constructores permiten crear estas estructuras a partir de diferentes tipos de variables: diccionarios, listas... También permiten personalizar las etiquetas de los índices, y filtrar y reordenar las etiquetas de columnas. Veamos los métodos principales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.1  Creación de series  \n",
    "\n",
    "El constructor para la creación de una serie pandas es `pandas.Series`. Este constructor acepta tres parámetros principales:\n",
    "\n",
    "* data: estructura de datos tipo array, iterable, diccionario o valor escalar que contendrá los valores a introducir en la serie.  \n",
    "* index: estructura tipo array con la misma longitud que los datos. Si este argumento no se añade al crear la serie, se agregará un índice por defecto formado por números enteros desde 0 hasta n-1, siendo n el número de datos.  \n",
    "* dtype: tipo de datos para la serie. Si no se especifica, se inferirá a partir de los datos.  \n",
    "\n",
    "Los valores del índice, como ya se ha comentado anteriormente, no tienen que ser necesariamente distintos aunque ciertas operaciones pueden generar un error si no soportan la posibilidad de tener índices duplicados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.1.1 *Creación de una serie a partir de una lista o de un array NumPy*\n",
    "\n",
    "En el siguiente ejemplo, estamos creando una serie simplemente a partir de una lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([7, 5, 3])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al no haberse especificado un índice, se asigna uno automáticamente con los valores 0, 1 y 2.  \n",
    "\n",
    "Si repetimos esta instrucción especificando un índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([7, 5, 3], index=[\"Ene\", \"Feb\", \"Mar\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... vemos cómo el índice por defecto ha sido sustituido por el indicado. En este caso, la longitud del índice deberá coindicir con el número de elementos de la lista.  \n",
    "\n",
    "Los mismos comentarios podrían hacerse si, en lugar de una lista, hubiésemos partido de un array NmPy para crear la serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy = np.array([7, 5, 3])\n",
    "print(numpy)\n",
    "s = pd.Series(numpy, index=[\"Ene\", \"Feb\", \"Mar\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.1.2 *Creación de una serie a partir de un diccionario*\n",
    "\n",
    "Si partimos de un diccionario para crear la serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"Ene\": 7, \"Feb\": 5, \"Mar\": 3}\n",
    "s = pd.Series(d)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...vemos cómo el constructor utiliza las claves como etiquetas del índice, y los valores del diccionario como valores de la serie.\n",
    "\n",
    "Si incluimos el índice explícitamente en el constructor, los valores en la serie se tomarán en el orden en el que estén en el índice explícito. Además, si en éste hay valores que no pertenecen al conjunto de claves del diccionario, se añaden a la serie con un valor NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"Ene\": 7, \"Feb\": 5, \"Mar\": 3}\n",
    "s = pd.Series(d, index = [\"Abr\", \"Mar\", \"Feb\", \"Ene\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, hemos creado la serie especificando el índice que hemos formado dando la vuelta a las claves del diccionario (\"Mar\", \"Feb\" y \"Ene\") y hemos añadido a la lista de etiquetas el valor \"Abr\", que no pertenece al conjunto de claves del diccionario. Se ha añadido a la serie, pero se le ha asignado el valor NaN. Es precisamente la presencia de este valor lo que modifica el tipo de la serie a float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.1.3 *Creación de una serie a partir de un escalar*\n",
    "  \n",
    "  Si los datos se reducen a un escalar (no a una lista con un único elemento, sino a un sencillo escalar como 7 o 15.4) será necesario añadir el índice explícitamente. El número de elementos de la serie coincidirá con el número de elementos del índice, y el escalar será asignado como valor a todos ellos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series (7, index = [\"Ene\", \"Feb\", \"Mar\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.1  Creación de dataframes  \n",
    "\n",
    "El constructor de dataframes es `pandas.DataFrame`. Acepta cuatro parámetros principales:\n",
    "\n",
    "* data: estructura de datos ndarray (array NumPy), diccionario u otro dataframe.\n",
    "* index: índice a aplicar a las filas. Si no se especifica, se asignará uno por defecto formado por números enteros entre 0 y n-1, siendo n el número de filas del dataframe.\n",
    "* columns: etiquetas a aplicar a las columnas. Al igual que ocurre con el índice de filas, si no se añade se asignará uno automático formado por números enteros entre 0 y n-1, siendo n el número de columnas.\n",
    "* dtype: tipo a aplicar a los datos. Solo se permite uno. Si no se especifica, se infiere el tipo de cada columna a partir de los datos que contengan.  \n",
    "\n",
    "Los valores de los índices de filas y columnas no tienen por qué ser necesariamente distintos.  \n",
    "\n",
    "Veamos algunas de las estructuras a partir de las que es posible construir un dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.2.1 *Creación de un dataframe a partir de un diccionario de listas*\n",
    "\n",
    "En este escenario partimos del siguiente diccionario de listas de valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elementos = {\n",
    "                \"Número atómico\": [1 , 6, 47, 88],\n",
    "                \"Masa atómica\": [1.088, 12.011, 107.87, 226],\n",
    "                \"Familia\": [\"No metal\", \"No metal\", \"Metal\", \"Metal\"]\n",
    "}\n",
    "elementos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y creamos el dataframe con él como primer argumento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tabla_periodica = pd.DataFrame(elementos)\n",
    "df_tabla_periodica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataframe se ha creado situando las claves del diccionario como etiquetas de columnas y las listas asociadas a cada clave como columnas del dataframe. Al no haber especificado un índice de filas, éste ha tomado valores por defecto (0, 1, 2 y 3).\n",
    "\n",
    "A continuación repetimos la misma operación especificando las etiquetas tanto para filas como para columnas, utilizando los parámetros index y columns, respectivamente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tabla_periodica = pd.DataFrame(  \n",
    "                                    elementos,\n",
    "                                    index = [\"H\", \"C\", \"Ag\", \"Ra\"],\n",
    "                                    columns = [\"Familia\", \"Número atómico\", \"Masa atómica\"]\n",
    "                                )\n",
    "df_tabla_periodica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que con el parámetro columns podemos especificar el orden en el que se mostrarán las columnas o incluso filtrar éstas (no incluyendo todas las etiquetas presentes en el diccionario como claves), pero no cambiar sus nombres. De hecho, ya se ha comentado que si alguna de las etiquetas incluidas en dicho argumento no apareciese en el conjunto de claves del diccionario, se crearía una columna con dicho nombre pero con todos sus valores fijados a NaN.\n",
    "\n",
    "Si, en lugar de listas de datos como valores del diccionario, hubiesen sido arrays NumPy o series, el procedimiento habría sido exactamente el mismo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.2.2 *Creación de un dataframe a partir de un array de Numpy*\n",
    "\n",
    "En el caso de partir de un array NumPy, si no se especifican las etiquetas de filas y columnas, se asignan las etiquetas por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unidades_datos = np.array([ \n",
    "                            [2, 5, 3, 2],\n",
    "                            [4, 6, 7, 2],\n",
    "                            [3, 2, 4, 1]\n",
    "                        ])\n",
    "unidades_datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unidades = pd.DataFrame(unidades_datos)\n",
    "df_unidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las filas del array NumPy siguen siendo interpretadas como filas del dataframe.\n",
    "\n",
    "Si especificamos las etiquetas de filas y columnas, el resultado es diferente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unidades = pd.DataFrame(\n",
    "                            unidades_datos,\n",
    "                            index = [2015, 2016, 2017],\n",
    "                            columns = [\"Ag\", \"Au\", \"Cu\", \"Pt\"]\n",
    "                        )\n",
    "df_unidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.2.3 *Creación de un dataframe a partir de una lista de diccionarios*\n",
    "\n",
    "También podemos partir de un conjunto de diccionarios, cada uno definiendo el contenido de lo que será una fila del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unidades_2015 = {\"Ag\": 2, \"Au\": 5, \"Cu\": 3, \"Pt\": 2}\n",
    "unidades_2016 = {\"Ag\": 4, \"Au\": 6, \"Cu\": 7, \"Pt\": 2}\n",
    "unidades_2017 = {\"Ag\": 3, \"Au\": 2, \"Cu\": 4, \"Pt\": 1}\n",
    "\n",
    "df_unidades = pd.DataFrame([unidades_2015, unidades_2016, unidades_2017], index = [2015, 2016, 2017])\n",
    "\n",
    "df_unidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los diccionarios deberán compartir el mismo conjunto de claves que se interpretarán como etiquetas de columnas. Si las etiquetas no coinciden, se crearán todas las columnas pero se asignarán NaN a los valores desconocidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unidades_2015 = {\"Ag\": 2, \"Au\": 5, \"Cu\": 3, \"Pt\": 2}\n",
    "unidades_2016 = {\"Ag\": 4, \"Au\": 6, \"Cu\": 7, \"Pt\": 2}\n",
    "unidades_2017 = {\"Ag\": 3, \"Pb\": 2, \"Cu\": 4, \"Pt\": 1}\n",
    "\n",
    "df_unidades = pd.DataFrame([unidades_2015, unidades_2016, unidades_2017], index = [2015, 2016, 2017])\n",
    "\n",
    "df_unidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, el año 2017 tiene una clave, Pb, que no existe en los otros dos diccionarios. Y este mismo año carece de la clave Au que sí se encuentra en los otros dos. Vemos cómo los datos no coincidentes se han rellenado con NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.2.4 *Otros métodos*\n",
    "\n",
    "Además de poder partir de otras estructura y de las vistas (de un diccionario de tuplas, por ejemplo), hay dos constructores adicionales:  \n",
    "\n",
    "* `pandas.DataFrame.from_dict`: que crea un dataframe a partir de un diccionario de diccionarios o de secuencias tipo array. \n",
    "* `pandas.DataFrame.from_records`: que parte de una lista de tuplas o de arrays NumPy con un tipo estructurado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Creación de dataframes a partir de distintos origenes de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3.1 CSV\n",
    "\n",
    "La principal función ofrecida por pandas para la lectura de datos desde un fichero es `pandas.read_csv`. Esta función lee un fichero de valores separados por comas (formato CSV) y lo vuelca en un dataframe, incluyéndo gran candidad de parámetros para determinar cómo se realiza la lectura y cómo deberán tratarse los datos leídos. Los más destacados son los siguientes:\n",
    "\n",
    "* header: Este parámetro determina qué fila o filas se usarán como etiquetas de columnas. Por defecto se usarán los valores de la primera línea del fichero. Si los datos no tienen cabecera, deberá indicarse por medio de header = None.\n",
    "* names: Lista de nombres de columnas a usar.\n",
    "* index_col: Columna a usar como índice de filas.\n",
    "* parse_dates: Determina si las columas conteniendo fechas pero estén en otros formatos (texto) deberán ser convertidas a formato de fechas o no.\n",
    "* nrows: Número del filas del fichero a leer. Útil si se desea leer un fichero en bloques.\n",
    "* compression: Especifica si deberá aplicarse un algoritmo de descompresión a los datos (\"zip\", \"gzip\", etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv(\"ficheros/wines_SPA.csv\")\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para escribir un dataframe en un fichero en formato CSV se usa la función `pandas.to_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_csv.to_csv(\"./ficheros/vinos_SPA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3.2 Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma de cargar un fichero excel es usando la función pandas.read_xsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel(\"./ficheros/wines_SPA.xlsx\")\n",
    "df_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para escribir un dataframe en un fichero en formato CSV se usa la función `pandas.to_excel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_excel.to_excel(\"./ficheros/vinos_SPA.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3.3 BBDD (Mysql)\n",
    "\n",
    "Para realizar la conexión usaremos la librería `sqlalchemy` que permite conectarnos contra las bbdd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos las credenciales de conexión a la bbdd para crear una cadena de conexión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_username=\"root\"\n",
    "db_password=\"root\"\n",
    "db_host=\"localhost\"\n",
    "db_name=\"vinos\"\n",
    "\n",
    "s = 'mysql+mysqlconnector://{0}:{1}@{2}/{3}'.format(db_username, db_password, db_host, db_name)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la conexión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(s)\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos la información desde una consulta y la volcamos a un dataframe usando la función `pandas.read_sql`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos = pd.read_sql('SELECT * FROM vinos', engine)\n",
    "df_vinos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y para escribir usamos el metodo `pandas.to_sql`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_vinos.to_sql(con=engine, name='vinos2', if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Inspección de datos en series y dataframes\n",
    "\n",
    "Normalmente, una vez hemos cargado un bloque de datos en una serie o un dataframe, lo primero que haremos será inspeccionarlo para confirmar que los datos cargados son los esperados y que la lectura se ha realizado correctamente. Para esto tenemos los métodos `head, tail y sample`, con un comportamiento semejante en series y dataframes, que nos muestran un subconjunto de los datos cargados.  \n",
    "\n",
    "Además, los métodos `describe e info` nos proporcionan información adicional sobre los datos. Veamos estos métodos por separado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.4.1 `head`\n",
    "\n",
    "Este método, `pandas.Series.head` para series y `pandas.DataFrame.head` para dataframes, devuelve los primeros elementos de la estructura (los primeros valores en el caso de una serie y las primeras filas en el caso de un dataframe). Por defecto, se trata de los 5 primeros elementos, pero podemos especificar el número que deseamos como argumento de la función. Por ejemplo, partamos de las siguientes estructuras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_entradas = pd.Series(  \n",
    "                        [11, 18, 12, 16, 9, 16, 22, 28, 31, 29, 30, 12],\n",
    "                        index = [\"ene\", \"feb\", \"mar\", \"abr\", \"may\", \"jun\", \"jul\", \"ago\", \"sep\", \"oct\", \"nov\", \"dic\"]\n",
    "\n",
    ")\n",
    "s_entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_salidas = pd.Series(  \n",
    "                        [9, 26, 18, 15, 6, 22, 19, 25, 34, 22, 21, 14],\n",
    "                        index = [\"ene\", \"feb\", \"mar\", \"abr\", \"may\", \"jun\", \"jul\", \"ago\", \"sep\", \"oct\", \"nov\", \"dic\"]\n",
    "\n",
    ")\n",
    "s_salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacen = pd.DataFrame({\"entradas\": s_entradas, \"salidas\": s_salidas})\n",
    "df_almacen[\"neto\"] = df_almacen.entradas - df_almacen.salidas\n",
    "df_almacen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo estamos mostrando todos los elementos de la estructura pues son 12. En un caso real podemos estar hablando de miles o de millones.\n",
    "\n",
    "Ahora, para mostrar apenas los primeros elementos de la estructura, ejecutamos el método `head`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_entradas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podríamos seleccionar el número filas empezando desde el principio que queremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_entradas.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacen.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4.2 `tail`\n",
    "\n",
    "Los métodos `pandas.Series.tail` (para series) y `pandas.DataFrame.tail` (para dataframes) son semejantes a los anteriores, pero muestran los últimos elementos de la estructura. Si no indicamos otra cosa como argumento, serán los 5 últimos elementos los que se muestren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_entradas.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacen.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en el método anterior, también podremos seleccionar el número filas empezando desde el final que queremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_entradas.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacen.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4.3 `sample`  \n",
    "\n",
    "Sin embargo, es frecuente que los datos que hayamos leído estén ordenados según algún criterio, y que el bloque de datos mostrado por los métodos head o tail estén formados por datos muy parecidos. Y en ocasiones nos puede convenir ver datos aleatorios de nuestra estructura. Para esto podemos utilizar los métodos `pandas.Series.sample` para series y `pandas.DataFrame.sample` para dataframes. Al contrario que head o tail, el número de elementos devueltos por defecto es uno, por lo que, si deseamos extraer una muestra mayor, tendremos que indicarlo como primer argumento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_entradas.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacen.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4.4 `describe`  \n",
    "\n",
    "El método `describe` devuelve información estadística de los datos del dataframe o de la serie (de hecho, este método devuelve un dataframe). Esta información incluye el número de muestras, el valor medio, la desviación estándar, el valor mínimo, máximo, la mediana y los valores correspondientes a los percentiles 25% y 75%.\n",
    "\n",
    "Siguiendo con el ejemplo visto en la sección anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacen.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método acepta el parámetro **percentiles** conteniendo una lista (o semejante) de los percentiles a mostrar. También acepta los parámetros include y exclude para especificar los tipos de las características a incluir o excluir del resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacen.describe(percentiles=[0.9, 0.95, 0.98], include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4.5 `info`  \n",
    "\n",
    "El método info muestra un resumen de un dataframe, incluyendo información sobre el tipo de los índices de filas y columnas, los valores no nulos y la memoria usada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacen.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacen.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4.6 `value_counts`  \n",
    "\n",
    "Un método de las series pandas extremadamente útil es `pandas.Series.value_counts`. Este método devuelve una estructura conteniendo los valores presentes en la serie y el número de ocurrencias de cada uno. Estos valores se muestran en orden decreciente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([3, 1, 2, 1, 1, 4, 1, 2, np.nan])\n",
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede apreciarse, por defecto no se incluyen los valores nulos. Este comportamiento puede modificarse haciendo uso del parámetro dropna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Selección de datos en series y dataframes  \n",
    "\n",
    "Un aspecto relativamente complejo involucrado en el uso de las **series y los dataframes** -principalmente con esta última estructura- es la extracción o selección de datos. Esta relativa complejidad viene derivada principalmente de la abundancia de alternativas y de las excepciones a la norma que algunas de ellas aparentan ser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5.1 Selección de datos en series  \n",
    "\n",
    "Ya se ha comentado que una serie pandas consta de un array de datos y un array de etiquetas (el índice o index). Si al crear la serie no se ha especificado el índice, ya sabemos que se asignará uno implícito por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos seleccionar los valores haciendo referencia al índice asignado con la misma notación que en un diccionario (la llamada \"notación corchetes\" o \"square bracket notation\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s[0])\n",
    "print(s[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando esta sintaxis, si no se ha especificado un índice explícito, los índices negativos no están permitidos.\n",
    "\n",
    "Si se asignan índices de forma explícita:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], index = [\"a\", \"b\", \"c\", \"d\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando esta sintaxis, si no se ha especificado un índice explícito, los índices negativos no están permitidos.\n",
    "\n",
    "Si se asignan índices de forma explícita:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s[\"a\"], s[0])\n",
    "print(s[\"d\"], s[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta sintaxis, sí está permitido hacer uso de índices negativos para referirnos a los elementos desde el final de la estructura.\n",
    "\n",
    "Si los índices asignados son números enteros (al igual que las etiquetas del índice implícito), el índice implícito queda desactivado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(s[-1])\n",
    "except KeyError as e:\n",
    "    print(\"Error: \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], index = [3, 2, 1, 0])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=''\n",
    "try:\n",
    "    print(s[-1])\n",
    "except KeyError as e:\n",
    "    print(\"Error: \" + str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.1.1 Uso de rangos  \n",
    "\n",
    "Siguiendo con esta la notación tipo diccionario, es posible seleccionar rangos de valores. De esta forma, si usamos un rango numérico en una serie en la que hemos definido un índice explícito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], index = [\"a\", \"b\", \"c\", \"d\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...observamos que el rango se interpreta como haciendo referencia al índice implícito, y se incluyen los valores desde el primer índice incluido, hasta el último sin incluir.\n",
    "\n",
    "Si no se incluye alguno de los límites, el comportamiento es el estándar en Python (si no se incluye el primer valor, se consideran todos los elementos desde el principio, y si no se incluye el último valor, se consideran todos los elementos hasta el final):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se utilizan los índices explícitos en el rango, el comportamiento es ligeramente diferente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"a\":\"c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos cómo se incluyen los valores desde el primer índice hasta el último índice, **ambos incluidos**.\n",
    "\n",
    "Aquí también podemos obviar el uso de alguno de los dos límites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[:\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"b\":]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una posible fuente de confusión viene derivada del hecho de que, usando rangos, es posible hacer referencia tanto a las etiquetas como a los índices numéricos.  \n",
    "\n",
    "Si utilizamos etiquetas, hacemos referencia a las etiquetas (por supuesto):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], index = [\"a\", \"b\", \"c\", \"d\"])\n",
    "s[\"b\":\"c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..y, por tanto, si utilizamos números, hacemos referencia a los índices numéricos (¿por supuesto...?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], index = [\"a\", \"b\", \"c\", \"d\"])\n",
    "s[\"b\":\"d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y qué ocurre si nuestras etiquetas son números? Pues que siempre que usemos rangos con números estaremos haciendo referencia a los índices numéricos: no es posible hacer referencia a las etiquetas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], index = [3, 2, 1 , 0])\n",
    "s[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, algo s[1] como devolverá el valor cuya etiqueta es 1 (si existe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...o el valor cuya posición es 1 si dicha etiqueta no existe y el índice explícito no es numérico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], index = [\"a\", \"b\", \"c\", \"d\"])\n",
    "s[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es debido a esto que existen los métodos loc e iloc que veremos poco más adelante. Dichos métodos hacen una referencia explícita a etiquetas o posiciones, respectivamente, eliminando cualquier duda al respecto de su interpretación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.1.2 Uso de listas  \n",
    "\n",
    "Al igual que con los array NumPy, es posible indicar, no un elemento simple ni un rango, sino una lista de valores. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[[3, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, la lista contiene los números 3 y 1, y son los valores correspondientes a estos índices -y en el orden especificado- los devueltos por la instrucción.\n",
    "\n",
    "El resultado devuelto sigue siendo una serie pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(s[[3, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta notación, en el caso de que la serie tenga un índice explícito numérico, los valores de la lista se interpretan como haciendo referencia al índice explícito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.1.3 `get`  \n",
    "\n",
    "También podemos usar el método `pandas.Series.get` para extraer un valor de forma segura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.get(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.get(7, default=\"No existe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la clave indicada no existe, la función devuelve None por defecto (es posible personalizar este valor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.1.4 `loc` \n",
    "\n",
    "Las series pandas y los dataframes disponen de los versátiles métodos loc e iloc:\n",
    "\n",
    "El método `pandas.Series.loc` permite seleccionar un grupo de elementos por etiquetas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uso con etiqueta simple.  \n",
    "Como argumento de este método puede utilizarse una única etiqueta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], index =[\"a\", \"b\", \"c\", \"d\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[\"b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el argumento se interpreta siempre como etiqueta del índice, nunca como posición en dicho índice aun cuando se pase un número entero que no pertenece al conjunto de etiquetas y pueda representar una posición válida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uso con lista de etiquetas  \n",
    "También podemos pasar al método una lista de etiquetas, en cuyo caso se extraen los valores correspondientes a dichas etiquetas y en el orden en el que se incluyen en la lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[[\"d\",\"a\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uso con rangos  \n",
    "Otra opción es pasar al método un rango:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[\"b\":\"d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso es importante recalcar que, tal y como se ve en la imagen anterior, el método va a devolver todos los elementos entre los límites indicados **ambos incluidos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.1.5 `iloc`\n",
    "\n",
    "El método `pandas.Series.iloc` permite extraer datos de la serie a partir de los índices implícitos que éstos tienen asignados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uso con un número entero  \n",
    "La opción más simple es utilizar como argumento un simple número entero (el primer elemento de la serie recibe el índice cero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], index =[\"a\", \"b\", \"c\", \"d\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el número es negativo, hace referencia al final de la serie (en este caso, el último elemento recibe el índice -1) -y esto tanto si se ha especificado un índice explícito como si no-:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uso con lista o array de números\n",
    "Una segunda opción es pasar como argumento una lista o array de números, en cuyo caso se devuelven los elementos que ocupan dichas posiciones en el orden indicado en la lista o array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[[2,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos incluir en esta lista números negativos, con la funcionalidad ya comentada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[[-2,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uso con rango de números \n",
    "Una tercera opción es usar como argumento un rango de números:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior podemos ver, si el rango tiene la forma a:b, se incluyen todos los elementos desde aquel cuyo índice es a (incluido) hasta el que tiene el índice b (sin incluir).\n",
    "\n",
    "Si no se especifica el primer valor, se consideran todos los elementos desde el principio de la serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y, si no se especifica el segundo valor, se consideran todos los elementos hasta el final de la serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También pueden usarse valores negativos para indicar el comienzo y/o el final del rango:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejercicio 2.3.1 ¿Que ocurre en la ejecución de la siguiente celda?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[-4,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contesta tu respuesta en esta celda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.1.6 Uso de arrays booleanos\n",
    "\n",
    "Una muy interesante opción para seleccionar elementos de una serie pandas es usar arrays booleanos. Por ejemplo, partimos de la siguiente serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([5, 2, -3, 7, 8, 4])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos seleccionar un conjunto de valores de la misma haciendo referencia al nombre de la serie y, entre los corchetes, una lista o array de booleanos (también puede ser una serie de booleanos, como veremos un poco más adelante):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[[True, False, False, True, True, False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso hemos seleccionado los elementos cuyos índices son 0, 3 y 4, que son los índices que ocupan los booleanos True en la lista de booleanos usada (lista cuya longitud deberá ser igual a la longitud de la serie pues, de no ser así, se devuelve un error).\n",
    "\n",
    "Esta lista o array de booleanos no tiene porqué ser especificada de forma explícita, puede ser el resultado de una expresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(s>2))\n",
    "s>2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, hemos usado la expresión s > 2 para generar una serie pandas de booleanos, serie en la que los valores toman el valor True cuando el valor con el mismo índice de s toma un valor mayor estricto que 2.\n",
    "\n",
    "Podemos entonces usar este resultado para extraer valores de la serie s (valores que serán aquellos mayores que 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[s>2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este mismo enfoque puede ser usado con los métodos `pandas.Series.loc` y `pandas.Series.iloc` ya vistos en las secciones anteriores con algún matiz adicional:\n",
    "\n",
    "El método `loc` puede ser usado tanto con un array explícito de booleanos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[[True, False, False, True, True, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[s>2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, el método `iloc` tiene un comportamiento ligeramente diferente. Puede ser usados con arrays explícitos de booleanos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[[True, False, False, True, True, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...pero el uso de expresiones que generen una serie pandas de booleanos devuelve un error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[s>2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el objeto que está generando la estructura de booleanos (s, en s > 2) fuese un array NumPy en lugar de tratarse de una serie pandas, sí sería posible usar el método `iloc`. De esta forma, la expresión s > 2 genera, como hemos visto, una serie pandas, pero podemos extraer los valores con el atributo values, que genera un array numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type((s>2).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(s>2).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si usamos esta expresión para realizar la selección en la serie original s, el resultado es ahora el correcto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[(s>2).values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es por ello que pandas recomienda usar el método `loc` cuando trabajemos con selección basada en booleanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.1.7 Selección aleatoria \n",
    "\n",
    "También podemos realizar una selección aleatoria a partir de una serie. El método `pandas.Series.sample` permite especificar o bien el número de elementos a extraer o bien la fracción del número total de elementos a extraer (parámetros n y frac, respectivamente), pudiendo especificar si la extracción se realiza con reemplazo o no (parámetro replace), los pesos a aplicar a cada elemento para realizar una extracción aleatoria ponderada (parámetro weights), y una semilla para el generador de números aleatorios que asegure la reproducibilidad de la extracción (parámetro random_state). Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], index =[\"a\", \"b\", \"c\", \"d\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sample(3, random_state = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos extraído 3 elementos, por defecto sin reemplazo, aplicando el valor 18 como semilla del generador de números aleatorios.  \n",
    "\n",
    "En el siguiente ejemplo se extraen el 60% de los valores de la serie original haciendo uso del parámetro frac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sample(frac = 0.6, random_state = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no hay reemplazo, el número máximo de elementos que podemos extraer coincide con la longitud de la serie. Pero si la extracción la realizamos con reemplazo, podemos especificar cualquier número de elementos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sample(10, random_state = 18, replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.1.8 `pop`\n",
    "\n",
    "El método `pandas.Series.pop` extrae y elimina un elemento de una serie cuyo índice se indica como argumento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...devolviendo un error en caso de que no exista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    s.pop(18)\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5.2 Selección de datos en dataframes  \n",
    "\n",
    "Desde un punto de vista semántico, un dataframe puede ser considerado semejante a un diccionario de series, en el que las claves son los nombres de las columnas y los valores, las columnas (que son series pandas). En este ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas = pd.DataFrame({\n",
    "                            \"Entradas\": [41, 32, 56, 18],\n",
    "                            \"Salidas\": [17, 54, 6, 78],\n",
    "                            \"Valoración\": [66, 54, 49, 66],\n",
    "                            \"Límite\": [\"No\", \"Sí\", \"No\", \"No\"],\n",
    "                            \"Cambio\": [1.43, 1.16, -0.67, 0.77]\n",
    "                        },\n",
    "                        index = [\"Ene\", \"Feb\", \"Mar\", \"Abr\"]\n",
    "\n",
    ")\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...podemos utilizar la sintaxis de los diccionarios para seleccionar la columna Entradas. Puede verse en la siguiente imagen cómo dicha columna es extraída con tipo de serie pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_ventas[\"Entradas\"]))\n",
    "df_ventas[\"Entradas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto significa que podemos realizar una selección en dicho resultado para, por ejemplo, extraer el valor correspondiente a febrero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[\"Entradas\"][\"Feb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, la más que razonable opción de eliminar los corchetes que separan ambos índices y sustituirlos por una coma no funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[\"Entradas\", \"Feb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si, una vez seleccionada una columna, le asignamos una lista o array (o serie) de valores de la misma longitud, estamos modificando dicha columna del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[\"Entradas\"] = [33, 25, 40, 12]\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si asignamos un único valor escalar, este se propaga por toda la columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[\"Salidas\"] = 1\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si estuviésemos asignando un array cuya longitud no coincidiese con la de la columna (y no estuviésemos asignando un escalar), obtendríamos un error.\n",
    "\n",
    "Si asignamos una serie pandas se consideran los índices del dataframe y de la serie, haciendo coincidir los valores cuyos índices sean los mismos en ambas estructuras (si dicha columna no existe, se crea). En el caso de que haya valores en la serie con índices que no se encuentren en el dataframe, se descartan. Y en el caso de que haya índices en el dataframe que no se encuentren en la serie, se asigna un valor NaN.\n",
    "\n",
    "Así, en el siguiente ejemplo, estamos añadiendo una serie cuyos índices son \"Ene\", \"Mar\", \"Abr\" y \"May\". Es decir, la serie no tiene un valor para el índice \"Feb\" que sí se encuentra en el dataframe (se asigna un NaN), e incluye el índice \"May\" que no se encuentra en el dataframe y se descarta:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[\"Perdidas\"] = pd.Series([5, 4, 6, 8], index = [\"Ene\", \"Mar\", \"Abr\", \"May\"])\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores asignados pueden proceder del propio dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[\"Ganancias\"] = (df_ventas[\"Entradas\"] * 2) - (df_ventas[\"Valoración\"]/10)\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos acceder a una columna con la llamada \"notación punto\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.Ganancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.2.1 Uso de rangos  \n",
    "\n",
    "El uso de un rango numérico entre los corchetes realiza una selección de filas, lo que puede parecer una cierta incoherencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(18).reshape([6,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El equipo de pandas lo justifica diciendo que esta sintaxis resulta extremadamente conveniente al tratarse de un tipo de selección frecuentemente usada. Esto es cierto, pero el hecho de que selecciones aparentemente semejantes (df[1,2], df[[1, 2]], df[1:3, 5], etc.) devuelvan un error no facilita su comprensión.\n",
    "\n",
    "En todo caso, vemos en la celda anterior que se devuelven las filas entre el primer valor del rango (incluido) y el último (sin incluir). También podríamos haber usado las etiquetas del índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"b\":\"d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...aunque en este caso la selección incluye tanto la fila correspondiente a la primera etiqueta como la fila correspondiente a la segunda.  \n",
    "\n",
    "También podemos obviar la inclusión del primer o del segundo valor, considerándose las filas desde el comienzo/hasta el final del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:\"c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.2.2 Uso de listas\n",
    "\n",
    "Si, al realizar la selección, situamos entre los corchetes una lista de etiquetas, estaremos seleccionando columnas en el orden en el que aparecen en la lista y con formato dataframe:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(18).reshape([6,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df[[\"C\", \"A\"]]))\n",
    "df[[\"C\", \"A\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.3.3 `get`\n",
    "\n",
    "También es posible extraer de forma segura una columna de un dataframe usando el método `pandas.DataFrame.get`. Éste extrae la columna indicada devolviendo un valor alternativo (por defecto None) si dicha columna no existe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(18).reshape([6,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get(\"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.3.4 `loc`\n",
    "\n",
    "Al igual que ocurre con las series, el método `pandas.DataFrame.loc` permite seleccionar un conjunto de filas y columnas por etiquetas. Este método acepta diferentes argumentos. Para probarlos, partamos del siguiente dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(18).reshape([6,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uso con etiqueta simple\n",
    "\n",
    "El primer escenario lo encontramos cuando usamos este método indicando una única etiqueta. En este caso estamos seleccionando la fila cuya etiqueta se indique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario mencionar que el argumento será siempre interpretado como etiqueta, aun cuando pueda estar representando un índice válido: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(12).reshape([4,3]),\n",
    "                    index = [1, 3, 0, 4],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por supuesto, si dicha etiqueta no existe, se devuelve un error (nuevamente, aun cuando la etiqueta sea un número que pueda estar representando un índice válido.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uso con lista de etiquetas  \n",
    "Si pasamos a loc una lista de etiquetas, estaremos extrayendo las filas cuyas etiquetas se indican, y en el orden en el que aparezcan en la lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(18).reshape([6,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[\"c\", \"a\", \"e\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al contrario de lo que ocurre cuando solo indicamos una etiqueta, el resultado es un dataframe. Y lo es aún cuando la lista contenga un único elemento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df.loc[[\"c\"]]))\n",
    "df.loc[[\"c\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uso con rangos  \n",
    "Otra opción es utilizar rangos limitados por etiquetas. De esta forma, si continuamos con el mismo ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[\"c\", \"a\"], [\"B\",\"C\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extracción de filas y columnas\n",
    "\n",
    "En los ejemplos vistos hasta ahora estamos extrayendo una o varias filas para todas las columnas. En posible, por supuesto, especificar qué filas y qué columnas exactas queremos extraer. Así, si utilizamos una única etiqueta para indicar la fila, y una única etiqueta para indicar la columna, separadas por una coma, estaremos extrayendo un único valor:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"a\", \"C\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos sustituir una de las dos etiquetas por el símbolo de dos puntos (:), lo que supondrá seleccionar todos los elementos de ese eje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"A\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto supone que, por ejemplo, las dos expresiones siguientes devuelven el mismo resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"b\", :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los métodos vistos pueden combinarse. Podemos, por ejemplo, seleccionar la intersección de las filas e y c (en este orden) y la columna B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[\"e\", \"c\"], \"B\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No solo se puede seleccionar las filas, sino que se pueden seleccionar también columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[\"c\", \"a\"], [\"B\",\"C\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.3.5 `iloc`  \n",
    "\n",
    "El método `pandas.DataFrame.iloc` permite realizar selecciones por posición. Tal y como cabría esperar, pueden utilizarse diferentes tipos de argumentos que determinan qué elementos se están extrayendo.  \n",
    "\n",
    "* Uso con un número entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(18).reshape([6,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número indicado siempre será tratado como posición, y no como etiqueta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(12).reshape([4,3]),\n",
    "                    index = [3, 2, 1, 0],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el número es negativo, hace referencia al final del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.3.6 Selección con índices y etiuetas simultáneamente \n",
    "\n",
    "En ocasiones nos encontraremos con que resultaría de utilidad poder realizar selecciones mezclando etiquetas e índices, y los métodos vistos, `loc` e `iloc`, solo permiten el uso de etiquetas o de índices, respectivamente. Para poder mezclar ambos tipos de referencias podemos recurrir a los métodos `pandas.Index.get_loc` y `pandas.Index.get_indexer`, métodos asociados a los índices de un dataframe:\n",
    "\n",
    "* El primero, `get_loc`, devuelve el índice de la etiqueta que se adjunte como parámetro.  \n",
    "* El segundo, `get_indexer`, devuelve un array con los índices de las etiquetas que se adjunten en forma de lista como parámetro.  \n",
    "\n",
    "Por ejemplo, partimos del siguiente dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(18).reshape([6,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si aplicamos los métodos comentados al índice de columnas haciendo referencia a etiquetas de columnas, obtenemos los siguientes resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.get_loc(\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.get_indexer([\"A\", \"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el primer caso hemos pasado la etiqueta \"B\" y el método ha devuelto su índice (1). En el segundo caso hemos pasado una lista de etiquetas y hemos obtenido un array con sus índices.\n",
    "\n",
    "Si ejecutamos estos métodos en el índice de filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.get_loc(\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.get_indexer([\"c\", \"e\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...obtenemos resultados semejantes.\n",
    "\n",
    "Ahora que sabemos cómo convertir etiquetas en sus índices equivalentes, podemos seleccionar datos de un dataframe mezclando etiquetas e índices si convertimos las etiquetas y utilizamos el método iloc ya visto. Por ejemplo, si quisiéramos extraer del anterior dataframe el dato que ocupa la fila \"c\" y la columna de índice 2, podríamos conseguirlo del siguiente modo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[df.index.get_loc(\"c\"), 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O si deseásemos obtener de las filas 5 y 3 (en este orden) los valores correspondientes a las columnas C y A (en este orden), podríamos hacerlo con la siguiente expresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[5,3], df.columns.get_indexer([\"C\", \"A\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.3.7 Uso de listas de booleanos  \n",
    "\n",
    "Otro método especialmente útil para la selección es el uso de listas de booleanos. Nuevamente puede parecer un tanto incoherente aunque, en este caso, su uso sí es extremadamente conveniente. Veamos por qué:\n",
    "\n",
    "Si partimos del mismo dataframe usado en la sección anterior, podemos crear una lista de booleanos (que, por motivos puramente pedagógicos, asignamos a una variable, mask) y realizar la selección con ella entre los corchetes. Vemos a continuación que este método también selecciona filas del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(18).reshape([6,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = [True, False, True, False, False, True]\n",
    "\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El vector de booleanos deberá tener la misma longitud que el índice de filas (es decir, un booleano por fila) y la selección devolverá aquellas filas para las que el elemento correspondiente del vector tome el valor True.\n",
    "\n",
    "La verdadera potencia de este estilo de selección se pone de manifiesto cuando la máscara se genera a partir de los datos del propio dataframe. Por ejemplo, si queremos seleccionar las filas para las que el valor de la columna A sea mayor que 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.A>7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"A\"]>7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tipo de filtrados resultan muy frecuentes en entornos de análisis, de ahí que la posibilidad de realizarlos sin necesidad de recurrir a métodos adicionales (`loc`, `iloc` o `get`, por ejemplo) resulte tan conveniente.\n",
    "\n",
    "Aun así, esta técnica también es compatible con los métodos `loc` e `iloc``, con algún matiz adicional:\n",
    "\n",
    "* Con loc podemos usar directamente una expresión de comparación como la vista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"B\"]>6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, con iloc nos veremos obligados a extraer los valores del dataframe resultante de la comparación -tal y como ocurría con las series- pues, de otro modo, obtendremos un error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[(df[\"B\"]>6).values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evitamos problemas si, tal y como sugiere pandas, utilizamos siempre el método loc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.3.8 Selección aleatoria  \n",
    "\n",
    "Al igual que ocurre con las series, también los dataframes tienen un método que permite extraer elementos del mismo de forma aleatoria: `pandas.DataFrame.sample`. Este método permite especificar el número de elementos a extraer (o el porcentaje respecto del total, parámetros n y frac, respectivamente), si la extracción se realiza con reemplazo o no (parámetro replace), los pesos a aplicar a los elementos para realizar una extracción aleatoria ponderada (parámetro weights) y una semilla para el generador de números aleatorios que asegure la reproducibilidad de la extracción (parámetro random_state). También es posible indicar el eje a lo largo del cual se desea realizar la extracción (por defecto se extraen filas, correspondiente al eje 0).\n",
    "\n",
    "Veamos un ejemplo. Si partimos del siguiente dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(18).reshape([6,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...podemos extraer 3 filas de forma aleatoria, sin reemplazo (opción por defecto) y fijando como semilla del generador de números aleatorios el número 18, de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3, random_state = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si especificamos como eje el valor 1, estaremos extrayendo columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(2, random_state = 18, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si hacemos uso del parámetro frac, podemos especificar el porcentaje de elementos a extraer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac = 0.6, random_state = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.3.9 `pop`\n",
    "\n",
    "Otra forma de extraer datos es la proporcionada por el método pandas.DataFrame.pop, que extrae y elimina una columna de un dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(15).reshape([3,5]),\n",
    "                    index = [\"a\", \"b\", \"c\"],\n",
    "                    columns = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columna = df.pop(\"B\")\n",
    "columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.5.3.10 Resumen de métodos de selección"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cantidad de posibilidades que nos ofrece la librería pandas a la hora de extraer información de un dataframe puede resultar un tanto abrumadora. Veamos un resumen de las principales técnicas vistas y qué estamos extrayendo con cada una.  \n",
    "\n",
    "En la siguiente lista e representa una etiqueta, i un índice y b un booleano:\n",
    "\n",
    "|Notación|Formato|Extraemos|  \n",
    "|--------|-------|---------|\n",
    "|df[\"e\"]|Serie|Columna de etiqueta \"e\"|  \n",
    "|df[\"e1\"][\"e2\"]|Escalar|Valor de la columna de etiqueta \"e1\" y fila de etiqueta \"e2\"|\n",
    "|df[\"e\"][i]|Escalar|Valor de la columna de etiqueta \"e\" y fila de índice |\n",
    "|df[i1:i2]|DataFrame|Filas con índices desde i1 hasta i2-1|\n",
    "|df[\"e1\":\"e2\"]|DataFrame|Filas con etiquetas desde \"e1\" hasta \"e2\"|\n",
    "|df[[\"e1\", \"e2\", \"e3\"]]|DataFrame|Columnas cuyas etiquetas se incluyen en la lista, en el orden indicado|\n",
    "|df[[b1, b2, b3]]|DataFrame|Filas correspondientes a los booleanos que tomen el valor True|\n",
    "|df.get(\"e\")|Serie|Columna de etiqueta \"e\" (de forma segura)|\n",
    "|df.loc[\"e\"]|Serie|Fila con etiqueta \"e\"|\n",
    "|df.loc[[\"e1\", \"e2\", \"e3]]|DataFrame|Filas cuyas etiquetas se incluyen en la lista, en el orden indicado|\n",
    "|df.loc[\"e1\":\"e2\"]|DataFrame|Filas cuyas etiquetas van desde \"e1\" hasta \"e2\"|\n",
    "|df.loc[:, \"e\"]|Serie|Columna con etiqueta \"e\"|\n",
    "df.loc[:, [\"e1\", \"e2\", \"e3]]|DataFrame|Columnas cuyas etiquetas se incluyen en la lista, en el orden indicado|\n",
    "df.loc[:, \"e1\":\"e2\"]|DataFrame|Columnas cuyas etiquetas van desde \"e1\" hasta \"e2\"|\n",
    "df.loc[\"e1\", \"e2\"]|Escalar|Valor correspondiente a la fila con etiqueta \"e1\" y columna con etiqueta \"e2\"|\n",
    "df.iloc[i]|Serie|Fila cuyo índice es i|\n",
    "df.iloc[[i1, i2, i3]]|DataFrame|Filas cuyos índices se incluyen en la lista, en el orden indicado|\n",
    "df.iloc[i1:i2]|DataFrame|Filas cuyos índices van desde i1 hasta i2-1|\n",
    "df.iloc[:, i]|Serie|Columna cuyo índice es i|\n",
    "df.iloc[:, [i1, i2, i3]]|DataFrame|Columnas cuyos índices se incluyen en la lista, en el orden indicado|\n",
    "df.iloc[:, i1:i2]|DataFrame|Columnas cuyos índices van desde i1 hasta i2-1|\n",
    "df.iloc[i1, i2]|Escalar|Valor correspondiente a la fila con índice i1 y columna con índice i2|\n",
    " \n",
    "\n",
    "No se incluyen en el listado anterior combinaciones de estos métodos ni los métodos para la selección usando índices y etiquetas simultáneamente.\n",
    "\n",
    "Aunque, a primera vista, pueda parecer bastante confuso, es posible destacar algunas reglas básicas:\n",
    "\n",
    "* Cuando se usan los métodos `loc` o `iloc`, el primer argumento siempre hace referencia a filas y el segundo a columnas. Esto significa que si no se incluye el segundo argumento, siempre estaremos extrayendo filas.\n",
    "* El método `get` devuelve columnas.\n",
    "* Sin incluir los métodos `loc`, `iloc` y `get`, solo hay -en el listado anterior- dos formas de extraer columnas: usando como argumento una etiqueta y usando como argumento una lista de etiquetas.\n",
    "* Del punto anterior extraemos como corolario que cualquier otra notación va a devolver filas (el uso de rangos y el uso de listas de booleanos)  \n",
    "\n",
    "Y, de hecho, si de los cuatro puntos anteriores quitamos los dos primeros por obvios, nos quedan dos reglas muy simples:\n",
    "\n",
    "* El uso de una etiqueta o de una lista de etiquetas devuelve columnas\n",
    "* En otros casos se devuelven filas (rangos de números o de etiquetas, o listas de booleanos)  \n",
    "\n",
    "Y, al respecto del tipo de estructura devuelta (si es un escalar, una serie o un dataframe) también es posible identificar una regla: Salvo el caso más obvio en el que estemos extrayendo un valor resultante de la intersección de una fila y una columna, si la nomenclatura que estamos usado permite extraer más de una fila o de una columna (aunque estemos extrayendo solo una en un momento dado) devolverá siempre dataframes y, en caso contrario, series.\n",
    "\n",
    "Por ejemplo, el uso de rangos permite extraer más de una fila (o de una columna), de forma que su uso siempre devuelve un dataframe. Así, `df[\"e1\":\"e2\"]` siempre devolverá un dataframe, aunque en este ejemplo estemos usando el rango para extraer una única columna.\n",
    "\n",
    "Otro ejemplo: si estamos usando la notación `df.loc[:, \"e\"]`, estamos extrayendo una columna y solo una columna, y con esta notación (dos puntos para las filas y una etiqueta para columnas) nunca podríamos extraer más de una columna, de forma que el resultado de la extracción siempre será una serie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 Edición de datos en series y dataframes\n",
    "\n",
    "Ya han ido apareciendo diferentes formas de modificar los datos contenidos en las estructuras ofrecidas por pandas, o de añadir nuevos datos. Recopilemos y ampliemos esta información en una única sección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.6.1 Edición de series \n",
    "\n",
    "Podemos modificar un valor de una serie usando la notación corchetes, y haciendo referencia a índices o a etiquetas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4, 5], index = [\"a\", \"b\", \"c\", \"d\", \"e\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0] = -1\n",
    "s[\"b\"] = -2\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos asignar un valor a un rango, definido éste por índices o por etiquetas, asignándose dicho valor a cada uno de los elementos involucrados en el rango:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1:3] = 0\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"b\":\"f\"] = -2\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya hemos visto en más de una ocasión, si el rango está delimitado por números (haciendo referencia a la posición de los elementos), el último elemento del rango no se incluye. Por el contrario, si está delimitado por etiquetas, el último elemento sí se incluye.\n",
    "\n",
    "Al rango podemos asignar también una lista de valores, aunque en este caso la lista deberá tener el mismo número de elementos que el rango en cuestión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1:3] = [0,1]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"b\":\"d\"] = [10, 11, 12]\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si asignamos un valor haciendo referencia a una etiqueta que no existe en el índice, se añade dicha etiqueta al índice y se le asigna el valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"f\"] = 0\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto solo funciona con etiquetas. Si utilizamos un índice y éste no existe en la serie, se devolverá un error.\n",
    "\n",
    "Si usamos un rango con etiquetas y alguna de las etiquetas no existe, solo se asigna el valor a las existentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"f\":\"h\"] = 0\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, también podemos usar en la selección una lista -tanto de índices como de etiquetas-, en cuyo caso ya sabemos que estamos seleccionando los valores indicados en el orden indicado.  \n",
    "\n",
    "Por ejemplo, podemos usar la lista `[\"c\", \"a\"]` para asignar a los elementos correspondientes los valores 1 y 2, respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[[\"c\", \"a\"]] = [1, 2]\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si utilizamos índices, el resultado es semejante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[[1,0]] = [20, 21]\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.6.1.1 Eliminación de elementos: `drop`\n",
    "\n",
    "El método `pandas.Series.drop` devuelve una copia de la serie tras eliminar el elemento cuya etiqueta se especifica como argumento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3,4,5], index = [\"a\" , \"b\", \"c\", \"d\", \"e\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = s.drop(\"b\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo hemos pasado como único argumento la etiqueta del elemento a eliminar, y el método ha devuelto la serie sin dicho elemento. Si la etiqueta no se encontrase en la serie, se devolvería un error.\n",
    "\n",
    "También podemos pasar como argumento no una etiqueta, sino una lista de etiquetas. En este caso se eliminarán todos los elementos con dichas etiquetas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = s.drop([\"d\", \"a\"])\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsérvese que las etiquetas no tienen que estar en orden.\n",
    "\n",
    "El argumento inplace = True realiza la eliminación inplace (modificando directamente la serie).\n",
    "\n",
    "Este método exige el uso de etiquetas para seleccionar los elementos a eliminar. Esto significa que si en un momento dado necesitamos eliminar uno o más elementos por su índice, deberemos convertirlos en sus correspondientes etiquetas, lo que resulta extremadamente sencillo seleccionando los elementos adecuados del index. En el siguiente ejemplo, partimos del mismo ejemplo ya visto anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3,4,5], index = [\"a\" , \"b\", \"c\", \"d\", \"e\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisiéramos eliminar los elementos cuyos índices son 1 y 3, bastaría recordar que el atributo index devuelve todas las etiquetas y que s.index[[1, 3]] devuelve las correspondientes a dichos índices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index[[1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.drop(s.index[[1,3]], inplace = True)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.6.1.2 Eliminación de elementos: `pop`\n",
    "\n",
    "Otra forma que tenemos a nuestra disposición para eliminar un elemento de una serie es el método `pandas.Series.pop`. Al igual que con el método drop, éste solo acepta una etiqueta y devuelve el valor correspondiente a dicha etiqueta, eliminándolo de la serie in-place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3,4,5], index = [\"a\" , \"b\", \"c\", \"d\", \"e\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La invocación del método devuelve el valor asociado a la etiqueta eliminada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.pop(\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La serie original se modifica eliminado la etiqueta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la etiqueta no se encontrase en el index, el método devolvería un error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.6.1.3 `where`\n",
    "\n",
    "El método `pandas.Series.where` permite filtrar los valores de una serie de forma que solo los que cumplan cierta condición se mantengan. Los valores que no la cumplan son sustituidos por un valor (NaN por defecto):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.arange(0,10))\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos ahora que queremos filtrar los valores de s que sean pares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.where(s%2 == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que los valores que no cumplen la condición son sustituidos por NaN. Podemos modificar este valor de reemplazo pasando al método como segundo argumento el valor que queremos fijar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.where(s%2 == 0, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2 Ejercicio\n",
    "\n",
    "Dada la serie de los 10 primeros números (del 1 al 10), pasar a su valor negativo si son menores o iguales a 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.6.2 Edición de dataframes\n",
    "\n",
    "Hemos visto la gran variedad de formas que tenemos a nuestra disposición para seleccionar elementos o bloques de elementos de un dataframe, y cada una de estas selecciones puede ser utilizada para modificar los valores contenidos en el dataframe. Veamos algunos ejemplos:\n",
    "\n",
    "Podemos modificar un valor concreto usando los métodos `loc` o `iloc`, en función de que queramos usar sus etiquetas o índices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(12).reshape([4,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1,2] = -1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos modificar una columna completa seleccionándola y asignándole, por ejemplo, una lista con los nuevos valores. Si partimos del mismo ejemplo que en el caso anterior..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"] = [10, 20, 30, 40]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la longitud de la lista conteniendo los valores a insertar deberá coincidir con la longitud de la columna, salvo que en lugar de una lista se esté asignando un único valor, en cuyo caso se propagará a toda la columna.\n",
    "\n",
    "Si la selección es un bloque de datos de un tamaño arbitrario, nos encontramos en el mismo escenario: o bien insertamos datos con el mismo tamaño que la selección, o insertamos un único valor que se propagará a toda la selección. Veamos el primer caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(12).reshape([4,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"b\":\"c\", \"A\":\"B\"] = [[-1,-2],[-3,-4]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo hemos seleccionado un bloque de 2x2, y hemos insertado datos con una estructura de las mismas dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(12).reshape([4,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"b\":\"c\", \"A\":\"B\"] = -1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..y en este segundo caso hemos asignado un único valor a la misma selección.\n",
    "\n",
    "Nos hemos encontrado también con el caso de insertar datos en una columna o fila inexistente, en cuyo caso se crea y se le asignan los valores en cuestión.  \n",
    "\n",
    "En el primer caso (de columna inexistente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(12).reshape([4,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"D\"] = [10, 20, 30, 40]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y en el segundo (de fila inexistente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(12).reshape([4,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"e\"] = [10, 20, 30]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.6.2.1 Eliminación de elementos: `drop`\n",
    "\n",
    "El método `pandas.DataFrame.drop` elimina las filas o columnas indicadas y devuelve el resultado, permitiéndose diferentes criterios para especificarlas.\n",
    "\n",
    "El primer criterio consiste en indicar la lista de etiquetas a eliminar y el eje al que pertenecen. Partamos del siguiente dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    np.arange(16).reshape([4,4]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\"],\n",
    "                    columns = [\"A\", \"B\", \"C\", \"D\"]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos eliminar, por ejemplo, las filas cuyas etiquetas son \"a\" y \"c\" con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"a\", \"c\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsérvese que lo que se muestra es el resultado de eliminar las filas indicadas del dataframe. Éste no se modifica salvo que utilicemos el argumento inplace = True.\n",
    "\n",
    "Como el eje por defecto es el 0, la instrucción anterior es equivalente a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"a\", \"c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para eliminar columnas, habría que indicar el eje correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"A\", \"C\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra alternativa para especificar si estamos eliminando filas o columnas es utilizar directamente los parámetros index y columns. Así, otra forma de eliminar las filas \"a\" y \"c\" sería la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=[\"a\", \"c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el resultado es el mismo que antes, lógicamente-. Y para eliminar las columnas \"B\" y \"D\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"A\", \"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.6.2.2 `where` \n",
    "\n",
    "De forma semejante a las series, el método de los dataframes `where` filtra los valores contenidos en el dataframe de forma que solo los que cumplan cierta condición se mantengan. El resto de valores son sustituidos por un valor que, por defecto, es NaN.\n",
    "\n",
    "Por ejemplo, partimos del siguiente dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(12).reshape(-1,3), columns=[\"A\", \"B\", \"C\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora queremos filtrar los valores múltiplos de 2, por ejemplo, podemos hacerlo de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df%2 == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos aquellos valores que no son múltiplo de 2 son sustituidos por NaN. Si, por ejemplo, quisiéramos cambiar de signo a los valores que no cumplen la condición impuesta, lo haríamos así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df%2 ==0, -df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.3 Ejercicio\n",
    "\n",
    "Dado el dataframe de los primeros 16 números (del 1 al 16) ordenados en una matriz de 4x4, pasar a su valor negativo si son menores o iguales a 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.7 Unión de series y dataframes\n",
    "\n",
    "Frecuentemente nos encontramos con que los datos a analizar están repartidos entre dos o más bloques de datos, lo que nos obliga a unirlos, bien concatenándolos, o bien realizando un \"join\" entre las estructuras (uniones del mismo tipo que las realizadas en bases de datos). Revisemos las funciones asociadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.7.1 Unión de series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.7.1.1 `concat`  \n",
    "\n",
    "Un caso con el que nos encontramos con relativa frecuencia es aquel en el que queremos unir una serie a otra. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4, 5], index = [\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "r = pd.Series([10, 11, 12], index = [\"f\", \"g\", \"h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([s, r])\n",
    "print(type(t))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver en la celda anterior que el resultado es una serie pandas.\n",
    "\n",
    "Si especificamos como eje de concatenación el eje 1, pandas alineará los valores con idénticas etiquetas. En el siguiente ejemplo, las series a y b tienen algunas etiquetas comunes (y otras no). El resultado incluye todas las etiquetas asignando el valor NaN (\"Not a Number\") a aquellos valores desconocidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4, 5], index = [\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "r = pd.Series([10, 11, 12], index = [\"a\", \"b\", \"f\"])\n",
    "\n",
    "t = pd.concat([s,r], axis=1, sort =True)\n",
    "print(type(t))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(se ha utilizado el argumento sort = True para ocultar cierto aviso al respecto de un cambio en la funcionalidad de esta función en versiones futuras de la librería pandas)\n",
    "\n",
    "Como puede observarse, el resultado es un dataframe.\n",
    "\n",
    "Por otro lado, ya sabemos que las etiquetas del índice no tienen por qué ser diferentes, de forma que si estuviésemos concatenando series con etiquetas comunes en sus índices, el resultado sería equivalente a los vistos hasta ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4, 5], index = [\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "r = pd.Series([10, 11, 12], index = [\"a\", \"c\", \"h\"])\n",
    "pd.concat([s,r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo hemos concatenado dos series que tienen dos etiquetas comunes (\"a\" y \"c\"), y vemos que las dos apariciones de cada una de ellas se incluyen en el resultado de la concatenación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.7.2 Concatenación y unión de dataframes\n",
    "\n",
    "Ésta es otra de las áreas en las que la variedad de opciones puede resultar confusa. A modo de resumen, digamos que pandas ofrece dos principales funciones con este objetivo: `pandas.concat` y `pandas.merge`.\n",
    "\n",
    "* La función concat permite concatenar dataframes a lo largo de un determinado eje\n",
    "* La función merge permite realizar uniones (joins) entre dataframes tal y como se realizan en bases de datos. Esta función también está disponible como método: `pandas.DataFrame.merge`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.7.2.1 `concat`\n",
    "\n",
    "La función `pandas.concat` es la responsable de concatenar dos o más dataframes (y de todas las estructuras proveídas por pandas) a lo largo de un eje, con soporte a lógica de conjuntos a la hora de gestionar etiquetas en ejes no coincidentes.  \n",
    "\n",
    "Veamos un primer caso, el más sencillo posible, para el que partimos de los siguientes dos dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "                    np.arange(9).reshape([3,3]),\n",
    "                    index = [\"a\", \"b\", \"d\"],\n",
    "                    columns = [\"A\", \"B\", \"C\"]\n",
    ")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "                    np.arange(12).reshape([4,3]),\n",
    "                    index = [\"a\", \"b\", \"c\", \"e\"],\n",
    "                    columns = [\"B\", \"C\", \"D\"]\n",
    ")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si pasamos a la función concat ambos dataframes como primer argumento (en forma de lista), obtenemos el siguiente resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos cómo, por defecto, la concatenación se ha realizado a lo largo del eje 0 (eje vertical), uniendo los índices de fila de ambos dataframes, y alineando las columnas por su etiqueta. Los valores para los que no hay datos se han rellenado con NaN (opción correspondiente al argumento por defecto join: \"outer\").\n",
    "\n",
    "Si especificamos que la concatenación se realice a lo largo del eje 1 (eje horizontal), el resultado es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo semejante al primer ejemplo, se han introducido NaN's allí donde no había datos, y se han alineado las filas por su etiqueta.\n",
    "\n",
    "Estos dos ejemplos vistos son tipo \"Outer\" (opción por defecto), considerando todas las etiquetas de los dos dataframes aun cuando no sean comunes a ambos. Pero si especificamos el argumento join = \"Inner\", los resultados pasan a considerar solo las etiquetas comunes. Así, para el primer ejemplo visto tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2], join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "incluyendo solo las columnas B y C comunes a ambos dataframes. Y para el segundo ejemplo tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro ignore_index controla el índice a asignar al eje a lo largo del cuál se realiza la concatenación. Si este parámetro toma el valor False (por defecto), el eje de concatenación mantiene las etiquetas de los dataframes originales. Si toma el valor True, se ignoran dichas etiquetas y el resultado de la concatenación recibe un nuevo índice automático numérico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2], axis=1, join='inner', ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.7.2.2 `merge`\n",
    "\n",
    "La función `pandas.merge` nos permite realizar \"joins\" entre tablas. El join es realizado sobre las columnas o sobre las filas. En el primer caso, las etiquetas de las filas son ignoradas. En cualquier otro caso (joins realizado entre etiquetas de filas, o entre etiquetas de filas y de columnas), las etiquetas de filas se mantienen.\n",
    "\n",
    "Veamos un primer ejemplo. \n",
    "\n",
    "Partimos de dos tablas conteniendo las ventas y costes de producción para varios meses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Month\": [\"ene\", \"feb\", \"mar\", \"may\"],\n",
    "                        \"Sales\": [14, 8, 12, 17]\n",
    "                    }\n",
    ")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Month\": [\"feb\", \"ene\", \"mar\", \"abr\"],\n",
    "                        \"Cost\": [7, 6, 8, 5]\n",
    "                    }\n",
    ")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que ambos dataframes tienen una columna común (\"Month\") y varias filas comunes (\"ene\", \"feb\" y \"mar\").  \n",
    "Obsérvese que en df2 las filas no están ordenadas y que, en df1, el mes de enero tiene índice 0 mientras que, en df2, el mes de enero tiene índice 1.  \n",
    "\n",
    "Si aplicamos la función merge a estos dataframes con los valores por defecto, obtenemos el siguiente resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esos valores por defecto suponen que el join se realiza sobre las columnas comunes y tipo \"inner\" (considerando solo las filas con etiquetas comunes).\n",
    "\n",
    "Si especificamos que el join sea de tipo \"outer\", lo que definimos con el parámetro how, el resultado considerará todas las etiquetas presentes en ambos dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, se ha rellenado con NaN's los valores inexistentes. Otras opciones para el parámetro how son \"left\" y \"right\" (además de la opción por defecto, \"outer\").\n",
    "\n",
    "Ya se ha comentado que, por defecto, el join se realiza entre las columnas comunes. Esto es, sin embargo, controlable usando el parámetro on y especificando la columna o columnas a usar. Por ejemplo, consideremos los siguientes dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Month\": [\"ene\", \"ene\", \"feb\", \"feb\"],\n",
    "                        \"Product\": [\"A\", \"B\", \"A\", \"B\"],\n",
    "                        \"Sales\": [14, 8, 12, 17]\n",
    "                    }\n",
    ")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Month\": [\"ene\", \"ene\", \"feb\", \"feb\"],\n",
    "                        \"Product\": [\"A\", \"B\", \"A\", \"B\"],\n",
    "                        \"Cost\": [7, 6, 8, 5]\n",
    "                    }\n",
    ")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos columnas comunes, lo que supone que el resultado de un merge por defecto sería el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, para cada combinación de Mes-Producto se añadirían los valores de los campos de ventas y coste. Si quisiéramos que el join se realizase solo por uno de los campos, Product, por ejemplo, bastaría con especificarlo con el parámetro on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2, on=\"Product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además del campo utilizado para realizar el join (\"Product\"), al existir un campo común a ambos dataframes (\"Month\") que no se desea usar para el join, pandas añade un sufijo (configurable) a este campo en ambas tablas para poder diferenciarlo.\n",
    "\n",
    "También podría ocurrir que ambos dataframes no tuviesen columnas comunes (columnas con el mismo nombre) pero que, aun así, quisiéramos realizar el join por algunas de ellas.  \n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Month\": [\"ene\", \"feb\", \"mar\", \"may\"],\n",
    "                        \"Sales\": [14, 8, 12, 17]\n",
    "                    }\n",
    ")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "                    {\n",
    "                        \"MonthName\": [\"feb\", \"ene\", \"mar\", \"abr\"],\n",
    "                        \"Cost\": [7, 6, 8, 5]\n",
    "                    }\n",
    ")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al no haber columnas comunes, la ejecución de la función merge devolvería un error. En este caso podemos usar los parámetros left_on y right_on para especificar el campo a usar en la tabla de la izquierda del join y en la de la derecha, respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2, left_on=\"Month\", right_on=\"MonthName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos cómo se realiza el join correctamente y se mantienen las columnas originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.7.2.3 Join por índice de filas\n",
    "\n",
    "ueremos que el join considere los índices de las filas -y no los valores de las columnas- de alguno de los dataframes para realizar el join, podemos usar los parámetros left_index y right_index.\n",
    "\n",
    "Supongamos, por ejemplo, que partimos de los siguientes dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Month\": [\"ene\", \"feb\", \"mar\", \"may\"],\n",
    "                        \"Sales\": [14, 8, 12, 17]\n",
    "                    }\n",
    ")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Purchases\": [5, 9, 11, 2, 6]\n",
    "                    },\n",
    "                    index=[\"ene\", \"feb\", \"mar\", \"abr\", \"may\"]\n",
    ")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución de la función merge no sería posible -devolvería un error- pues no hay columnas comunes. En este caso querríamos que para el dataframe df1 se considerase la columna \"Month\" -usando el parámetro left_on- y para el dataframe df2 el índice -usando el parámetro right_index-, de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, left_on=\"Month\", right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.8 Operaciones con estructuras en pandas  \n",
    "\n",
    "Al basarse la biblioteca pandas en NumPy, todas las funciones universales de esta última funcionarán con pandas, pero con una particularidad: al aplicar operaciones unarias se conservan las etiquetas de filas y columnas, y en funciones binarias, se van a alinear las filas y columnas de las estructuras involucradas por sus etiquetas.\n",
    "\n",
    "No entraremos en mucho detalle en las funciones de operación con series y dataframes, por lo que las enumero a continuación las más comunes:\n",
    "\n",
    "|Operación|Descripción|\n",
    "|---------|-----------|\n",
    "|pandas.Series.add|Suma una serie a otra, elemento por elemento|\n",
    "|pandas.Series.sub|Resta una serie a otra, elemento por elemento|\n",
    "|pandas.Series.mul|Multipica una serie por otra, elemento por elemento|\n",
    "|pandas.Series.div|Divide una serie por otra, elemento por elemento|\n",
    "|pandas.Series.round|edondea los elementos de una serie al número de decimales indicado|\n",
    "|pandas.DataFrame.add|Suma los dos dataframes, elemento por elemento|\n",
    "|pandas.DataFrame.sub|Resta a un dataframe otro dataframe, elemento por elemento|\n",
    "|pandas.DataFrame.mul|Multiplica un dataframe por otro, elemento por elemento|\n",
    "|pandas.DataFrame.div|Divide un dataframe por otro, elemento por elemento|\n",
    "|pandas.DataFrame.mod|Devuelve el resultado de calcular el módulo de un dataframe y otro dataframe, elemento por elemento|\n",
    "|pandas.DataFrame.dot|Devuelve la multiplicación de las dos matrices representadas por los dos dataframes|\n",
    "|pandas.DataFrame.abs|Devuelve una copia del dataframe conteniendo el valor absoluto de cada uno de sus valores|\n",
    "\n",
    "Para más detalle de su funcionamiento, así como otras operaciones que se pueden realizar con Series y DataFrames, se puede consultar la API de pandas (ver bibliografía).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.8.1 Métodos de agregación y estadística\n",
    "\n",
    "Los dataframes poseen un útil método que devuelve información estadística sobre los valores contenidos en él: `pandas.DataFrame.describe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas = pd.DataFrame(\n",
    "                            {\n",
    "                                \"Entradas\": [41, 32, 56, 18],\n",
    "                                \"Salidas\": [17, 54, 6, 78],\n",
    "                                \"Valoración\": [66, 54, 49, 66],\n",
    "                                \"Límite\": [\"No\", \"Sí\", \"No\", \"No\"],\n",
    "                                \"Cambio\": [1.43, 1.16, -0.67, 0.77]\n",
    "                            },\n",
    "                            index = [\"Ene\", \"Feb\", \"Mar\", \"Abr\"]\n",
    ")\n",
    "\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se aprecia en la anterior imagen, este método devuelve el número de elementos no nulos por columna, el valor medio, la desviación estándar, el valor mínimo y el máximo, y los valores correspondientes a los percentiles 25, 50 y 75.\n",
    "\n",
    "Otras funciones estadísticas útiles disponibles como métodos de los dataframes son:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.8.1.1 `pandas.DataFrame.mean`\n",
    "\n",
    "Devuelve la media aritmética de los valores del dataframe a lo largo de un determinado eje (eje 0 -vertical- por defecto):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[[\"Entradas\", \"Salidas\", \"Valoración\", \"Cambio\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.8.1.2 `pandas.DataFrame.median`\n",
    "\n",
    "Devuelve la mediana de los valores del dataframe a lo largo de un determinado eje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[[\"Entradas\", \"Salidas\", \"Valoración\", \"Cambio\"]].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.8.1.3 `pandas.DataFrame.mode`\n",
    "\n",
    "Devuelve la moda de los valores del dataframe a lo largo de un determinado eje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[[\"Entradas\", \"Salidas\", \"Valoración\", \"Cambio\"]].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.8.1.4 `pandas.DataFrame.std`\n",
    "\n",
    "Devuelve la desviación estándar de los valores del dataframe a lo largo de un determinado eje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[[\"Entradas\", \"Salidas\", \"Valoración\", \"Cambio\"]].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.8.1.5 `pandas.DataFrame.var`\n",
    "\n",
    "Devuelve la varianza de los valores del dataframe a lo largo de un determinado eje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[[\"Entradas\", \"Salidas\", \"Valoración\", \"Cambio\"]].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.8.1.6 `pandas.DataFrame.pct_change`\n",
    "\n",
    "Devuelve el porcentaje de cambio de un valor con respecto a la fila anterior (también puede aplicarse a columnas usando el parámetro axis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[[\"Entradas\", \"Salidas\", \"Valoración\", \"Cambio\"]].pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.8.1.7 `pandas.DataFrame.nunique`\n",
    "\n",
    "Devuelve el número de elementos distintos a lo largo de un determinado eje. El parámetro dropna controla si se incluyen los NaN en el recuento o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[[\"Entradas\", \"Salidas\", \"Valoración\", \"Cambio\"]].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.9 Agrupaciones\n",
    "\n",
    "Las agrupaciones realizadas con el método de series y dataframes groupby son una herramienta un tanto más sofisticada pero extremadamente útil en ciertas circunstancias.  \n",
    "\n",
    "Controlaremos los posibles duplicados que puedan existir a la hora de realizar agrupaciones y como tratarlos.\n",
    "\n",
    "Haremos operaciones de agregación sobre los datos agrupados.\n",
    "\n",
    "También resulta muy útil la creación de tablas dinámicas a partir de un dataframe utilizando el método pivot_table. Veamos algunos ejemplos sencillos de estas funciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.9.1 Agrupaciones en series  \n",
    "\n",
    "El método que permite agrupar una serie es `pandas.Series.groupby`. En su sintaxis más básica, requiere el parámetro by o el parámetro level. Veamos ambos casos y partamos de la siguiente serie para probarlos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas = pd.Series([2, 4, 1, 6, 2], index=[\"A\", \"B\", \"C\", \"A\", \"C\"])\n",
    "s_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro by se usa para determinar los grupos. Puede ser una función -que se aplicará a todos los elementos del índice-, un diccionario o una serie -en cuyo caso serán los valores los que determinen los grupos.\n",
    "\n",
    "Para ver el método groupby en funcionamiento con una función que determine los grupos, definamos una que simplemente devuelva la concatenación del texto \"Grupo \" y el valor que recibe: recordemos que esta función se va a aplicar sobre el índice de la serie, es decir, sobre los elementos \"A\", \"B\", etc. La función devolverá, por lo tanto, \"Grupo A\", \"Grupo B\", etc. y serán estas etiquetas las que determinen los grupos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grupo(s):\n",
    "    return (f\"Grupo {s}\")\n",
    "\n",
    "s_ventas.groupby(by=grupo).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos comentado que el método puede también recibir como parámetro by un diccionario, en cuyo caso serán los valores los que determinen los nombres de los grupos a crear tras mapear las claves del diccionario con las etiquetas de la serie. En nuestro caso, las etiquetas de la serie son \"A\", \"B\", etc., por lo que podemos usar el siguiente diccionario para mapear estos valores con los nombres de los grupos a crear: \"Producto A\", \"Producto B\", etc. en este ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"A\": \"Producto A\", \"B\": \"Producto B\", \"C\": \"Producto C\"}\n",
    "s_ventas.groupby(by=d).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O simplemente agrupamos por los valores del índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ventas.groupby(level = 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.9.2 Agrupaciones en DataFrames  \n",
    "\n",
    "El método pandas.DataFrame.groupby tiene una funcionalidad semejante a la vista para series, con los condicionantes propios de los dataframes: es necesario indicar el eje que contiene el criterio por el que se va a realizar la agrupación. Comencemos con un ejemplo sencillo. Partimos del siguiente dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas = pd.DataFrame(\n",
    "                            {\n",
    "                                \"Producto\":[\"A\", \"B\", \"C\", \"B\", \"A\", \"A\"],\n",
    "                                \"Ventas\": [6, 2, 1, 4, 5, 2]\n",
    "                            }\n",
    ")\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de los dataframes, el parámetro by puede hacer referencia a una función, a un diccionario, a una etiqueta o a una lista de etiquetas. Si pasamos simplemente la etiqueta \"Producto\" para indicar que la agrupación se realice según los valores de esta columna, tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.groupby(by=\"Producto\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisiéramos realizar la agrupación por más de una columna, bastaría con pasar como argumento una lista con las etiquetas en cuestión.  \n",
    "\n",
    "Por ejemplo, consideremos el siguiente caso en el que tenemos las ventas clasificadas por categoría y producto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas = pd.DataFrame(\n",
    "                            {\n",
    "                                \"Categoría\": [1, 2, 1, 1, 2, 1],\n",
    "                                \"Producto\": [\"A\", \"B\", \"C\", \"B\", \"A\", \"A\"],\n",
    "                                \"Ventas\": [6, 2, 1, 4, 5, 2]\n",
    "                            }\n",
    ")\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.groupby(by=[\"Categoría\", \"Producto\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si las agrupaciones las quisieramos llevar al dataframe como columnas no como indices, deberíamos usar el parametro `as_index=False` así nos quedaría una representaciçon similar a como lo hacen las bbdd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.groupby(by=[\"Categoría\", \"Producto\"], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.9.3 Función agregación\n",
    "\n",
    "Cuando no queremos hacer la agrupación por un solo elemento o queremos crear varias columnas específicas con los agregados lo que haremos es invocar al método `pandas.DataFrame.aggregate`.\n",
    "\n",
    "Usando el ejemplo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas = pd.DataFrame(\n",
    "                            {\n",
    "                                \"Categoría\": [1, 2, 1, 1, 2, 1],\n",
    "                                \"Producto\": [\"A\", \"B\", \"C\", \"B\", \"A\", \"A\"],\n",
    "                                \"Ventas\": [6, 2, 1, 4, 5, 2]\n",
    "                            }\n",
    ")\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.groupby(by=[\"Categoría\", \"Producto\"], as_index=False).aggregate(\n",
    "                                                                            Sumatorio_de_Ventas= (\"Ventas\", \"sum\"),\n",
    "                                                                            Media_de_Ventas=(\"Ventas\", \"mean\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puede invocarse este método pasándole un diccionario con las variables y el método de agregación que se quiere aplicar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.groupby(by=[\"Categoría\", \"Producto\"], as_index=False).aggregate({\"Ventas\": [\"sum\", \"min\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.10 Gestión de duplicados\n",
    "\n",
    "Un problema habitual en los conjuntos de datos es la existencia de registros duplicados. La duplicidad puede ser del registro completo o solamente de unos elementos. \n",
    "\n",
    "Pandas nos ofrece dos operaciones relacionadas con duplicados:\n",
    "\n",
    "* La primera detecta registros duplicados en un dataframe `pandas.DataFrame.duplicated`\n",
    "* La segunda elimina los registros duplicados en un dataframe `pandas.DataFrame.drop_duplicates`\n",
    "\n",
    "Vamos a usar el siguiente dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas = pd.DataFrame(\n",
    "                            {\n",
    "                                \"Categoría\": [1, 2, 1, 1, 2, 1, 1],\n",
    "                                \"Producto\": [\"A\", \"B\", \"C\", \"B\", \"A\", \"A\", \"A\"],\n",
    "                                \"Ventas\": [6, 2, 1, 4, 5, 2, 6]\n",
    "                            }\n",
    ")\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.10.1 `pandas.DataFrame.duplicated`\n",
    "\n",
    "Esta función devuelve una serie de booleanos donde el campo True determina la fila de los elementos duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar este array para filtrar solo aquellas filas de duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[df_ventas.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver nos da únicamente el segundo duplicado, si quisieramos ver el primer duplicado usaríamos el parámetro `keep='last'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[df_ventas.duplicated(keep='last')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O si quisieramos ver los dos filas duplicadas `keep=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[df_ventas.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los duplicados pueden ser también parciales. Podemos seleccionar que haga la búsqueda en ciertas columnas. En este caso vamos a ver todos los duplicados que se producen en producto y categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas[df_ventas.duplicated(subset=['Producto', 'Categoría'],keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.10.2 `pandas.DataFrame.drop_duplicates`\n",
    "\n",
    "Esta funcionalidad se comporta de forma análoga a duplicated salvo que esta función devuelve el dataframe con los duplicados eliminados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.drop_duplicates(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordar que esta función admite el parámetro `inplace=True` para realizar los cambios sobre el mismo DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Ejercicio\n",
    "\n",
    "En el dataframe anterior eliminar todos los duplicados que se producen en producto y categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe la respuesta aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.11 Ordenación y clasificación\n",
    "\n",
    "Otras herramientas que pueden resultar útiles son aquellas que nos permiten ordenar las estructuras de datos de pandas -ordenación según los índices o según los valores- y las que permiten clasificar cada elemento de una estructura según su valor (rankings).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.11.1 Ordenación de series por índice\n",
    "\n",
    "El método `pandas.Series.sort_index` devuelve una copia de la serie ordenada según las etiquetas de forma ascendente. En el siguiente ejemplo partimos una serie de valores enteros cuyas etiquetas son también números enteros, y generamos una copia tras ordenarla según estos últimos valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([0, 1, 2, 3, 4], index = [3, 1, 5, 0, 4])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos realizar la ordenación en sentido descendente con el parámetro `ascending`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si los índices fuesen cadenas de texto, se ordenarían de la a a la z, dando a las mayúsculas mayor prioridad (siguiendo el criterio del estándar Unicode):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([0, 1, 2, 3, 4], index = [\"b\", \"d\", \"a\", \"B\", \"A\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.11.2 Ordenación de series por valor\n",
    "\n",
    "Si lo que deseamos es obtener una copia de una serie tras ordenarla según sus valores, el método `pandas.Series.sort_values` hace exactamente esto, permitiéndonos -entre otras cosas- escoger si la ordenación es ascendente -valor por defecto- o descendente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([7, 3, 6, 1, -4], index = [\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo anterior vemos cómo el método `sort_values` ha devuelto la serie s ordenada según sus valores de forma ascendente, de -4 hasta 7.  \n",
    "\n",
    "También podríamos haberla ordenado de forma descendente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.11.3 Clasificación de series\n",
    "\n",
    "El método `pandas.Series.rank` devuelve una serie conteniendo la clasificación o posición de cada valor de la serie original si fuesen ordenados de menor a mayor.  \n",
    "\n",
    "Veámoslo en funcionamiento. Partimos de la siguiente serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([4, 2, 0, 3, 6], index = [\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ejecutamos el método rank asociado a esta serie, el resultado es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(s.rank()))\n",
    "s.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la estructura devuelta es una serie pandas, y que está formada por la posición o clasificación de cada elemento en la serie original. Así, por ejemplo, el menor valor de s era el 0 correspondiente a la etiqueta \"c\", de forma que, en la serie resultante de aplicar el método rank, el valor correspondiente a la etiqueta \"c\" es 1. El segundo valor de la serie s era el correspondiente a la etiqueta \"b\", que se muestra con el valor 2 en el resultado de rank, y así sucesivamente. Es decir, los valores de la serie resultante son los números desde 1 hasta n, siendo n el número de elementos de la serie original.\n",
    "\n",
    "O, al menos, esto es así si no hay valores repetidos en la serie original pues, en ese caso, el método rank nos permite especificar cómo queremos clasificarlos, cosa que podemos hacer con el parámetro method. Por defecto, cada uno de los valores repetidos recibe el valor medio de las clasificaciones de cada uno de los valores suponiendo que se les aplicase como clasificación un número entero consecutivo. Es decir, si partimos de la siguiente serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([4, 2, 2, 3, 3, 3, 6], index = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...podemos ver que el valor 2 está repetido dos veces, y que el valor 3 está repetido tres veces.  \n",
    "\n",
    "Aplicamos el método rank con los argumentos por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ordenásemos los valores de la serie s de menos a mayor, el resultado sería el siguiente:\n",
    "\n",
    "2, 2, 3, 3, 3, 4, 5\n",
    "\n",
    "Es decir, los valores 2 ocuparían las posiciones 1 y 2. Su valor medio es 1.5, que es el valor que les asigna el método rank. \n",
    "\n",
    "Los valores 3 ocuparían las posiciones 3, 4 y 5, cuyo valor medio es 4, y éste es el valor que les asigna el método rank.\n",
    "\n",
    "En todo caso, el parámetro method del método nos permite escoger el criterio de asignación de la clasificación para valores repetidos.  \n",
    "En el siguiente ejemplo, escogeremos el menor valor (de los que recibirían si se asignasen valores no repetidos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.rank(method = 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos cómo se ha asignado a los dos valores correspondientes al menor valor (etiquetas \"b\" y \"c\") el valor 1 (mínimo de 1 y 2, posiciones que ocupan ambos números) y se ha asignado el valor 3 a los tres valores que ocupan las posiciones 3, 4 y 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.11.4 Ordenación de dataframes por índice  \n",
    "\n",
    "Los dataframes también tienen el mismo método que las series, `pandas.DataFrame.sort_index`, que devuelven una copia del mismo tras ordenarlo según las etiquetas a lo largo de un determinado eje.\n",
    "\n",
    "Comencemos con un ejemplo sencillo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    {\n",
    "                        \"C\": [-3, 5, 2],\n",
    "                        \"A\": [1, 0, 3],\n",
    "                        \"D\": [4, 3, -4],\n",
    "                        \"B\": [-2, 3, 1]\n",
    "                    },\n",
    "                    index = [\"c\", \"a\", \"b\"]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los índices del dataframe son de tipo texto y susceptibles de ser ordenados alfabéticamene, de la a a la z o viceversa (ya se ha comentado que las mayúsculas son situadas antes que las minúsculas en una ordenación ascendente).  \n",
    "\n",
    "Ordenamos el dataframe, por lo tanto, a lo largo del eje 0 (eje vertical) -opción por defecto si no se indica otra cosa-:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente, las filas han sido ordenadas según el índice de filas. Especifiquemos que la ordenación del dataframe df sea por el eje 1 (eje horizontal):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso vemos cómo han sido las columnas las que han sido ordenadas según sus etiquetas. Por supuesto, también tenemos la opción de recurrir al parámetro ascending para especificar el orden (ascendente o descendente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis = 1, ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `sort_index` no permite especificar más que un único eje, por lo que si deseásemos realizar una segunda ordenación a lo largo del otro eje, tendríamos que volver a aplicar el mismo método:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index().sort_index(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.11.5 Ordenación de dataframes por valor\n",
    "\n",
    "El método `pandas.DataFrame.sort_values` asociado a todo dataframe es el que nos va a permitir ordenarlo según sus valores.  \n",
    "En el caso de una estructura de dos dimensiones, hay dos elementos que van a definir cómo realizar la ordenación: el eje escogido (eje 0, por defecto) y, dentro de ese eje, qué fila o columna (o qué filas o columnas) van a determinar el orden de los datos.  \n",
    "\n",
    "Para ver algunos ejemplos, partamos del siguiente dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    {\n",
    "                        \"C\": [0, 3, 1, 5],\n",
    "                        \"A\": [3, 2, 2, 0],\n",
    "                        \"D\": [2, 4, 5, 6],\n",
    "                        \"B\": [1, 2, 2, 0]\n",
    "                    },\n",
    "                    index = [\"a\", \"b\", \"c\", \"d\"]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que queremos ordenar esta estructura según la columna A, es decir, según el eje vertical o eje 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = \"A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tratarse del eje por defecto, no ha sido necesario especificarlo mediante el parámetro axis. Las columnas (en este caso solo una) que determinan el criterio de ordenación se han indicado mediante el parámetro by (si se trata de una única fila o columna basta indicar el nombre de la misma. Si se tratase de más de una, habría que agregarlas en forma de lista). Por cierto, este método exige trabajar con etiquetas, no acepta índices.\n",
    "\n",
    "Las filas se han reordenado de forma que la columna A muestre sus valores ordenados de menor a mayor. Las filas cuyas etiquetas son \"b\" y \"c\" , al tener el mismo valor en la columna \"A\", reciben una ordenadión por defecto (la que imponga el código que, probablemente, deja el mismo orden en el que aparecen en el dataframe original). Si quisiéramos ordenar las filas también según una segunda columna, podríamos hacerlo fácilmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = [\"A\", \"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las filas \"b\" y \"c\", que en el ejemplo anterior no se ordenaban entre sí pues no había criterio alguno que lo impusiese, ahora sí se muestran ordenadas según la columna \"C\".\n",
    "\n",
    "Si deseásemos ordenar el dataframe según los valores de las filas \"a\" y \"b\", por ejemplo, y de mayor a menor, podríamos conseguirlo del siguiente modo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = [\"a\", \"c\"], axis = 1, ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso ha sido necesario especificar el eje de ordenación, al no tratarse del eje por defecto (argumento axis = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.11.6 Clasificación de dataframes\n",
    "\n",
    "De forma semejante a las series, los dataframes tienen el método `pandas.DataFrame.rank`, que devuelve la clasificación de cada valor a lo largo de un determinado eje.  \n",
    "\n",
    "Veámoslo en funcionamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "                    {\n",
    "                        \"A\": [3, 3, 1],\n",
    "                        \"B\": [1, 5, 2],\n",
    "                        \"C\": [3, 7, 2],\n",
    "                        \"D\": [7, 2, -1]\n",
    "                        \n",
    "                    },\n",
    "                    index = [\"Ene\", \"Feb\", \"Mar\"]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estructura devuelta por el método `rank` es otro dataframe, y el eje por defecto en el que se calculan las clasificaciones es el eje 0 (eje vertical). Vemos que el comportamiento es semejante al visto para las series (de hecho, podemos pensar que el método se aplica a cada columna por separado, siendo éstas, como sabemos, series).  \n",
    "\n",
    "Por ejemplo, la primera columna está formada por las cifras 3, 3 y 1, y la clasificación es 2.5, 2.5 y 1 respectivamente, sabiendo que el 2.5 es la media de las posiciones 2 y 3 que dichas cifras ocuparían si la serie original se ordenase de menor a mayor.\n",
    "\n",
    "También podemos aplicar el método a lo largo del eje 1 (eje horizonta):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rank(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, si consideramos la primera fila, los valores del dataframe original son 3, 1, 3 y 7, y su clasificación es 2.5, 1, 2.5 y 4, sabiendo nuevamente que el 2.5 es el valor medio de las posiciones 2 y 3 que ocuparían los valores repetidos (3) si se asignasen posiciones numéricas consecutivas.\n",
    "\n",
    "El método rank tiene -ya lo hemos visto para series- el parámetro `ascending` que controla el orden de los resultados (ascendente o descendente) y el parámetro `method` que controla el criterio de clasificación para valores repetidos.\n",
    "\n",
    "Aplicamos un método de cálculo del rango, en este caso el máximo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rank(axis = 1, method = 'max', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.12 Gestión de valores nulos\n",
    "\n",
    "Un aspecto crítico en todo análisis de datos es la gestión de los valores nulos, representados en pandas por la valor real NaN (\"Not a Number\").\n",
    "\n",
    "pandas ofrece diferentes funciones y métodos para gestionar estos valores. Veamos los más importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.1 `pandas.isnull` \n",
    "\n",
    "La función `pandas.isnull` devuelve una estructura con las mismas dimensiones que la que se cede como argumento sustituyendo cada valor por el booleano True si el correspondiente elemento es un valor nulo, y por el booleano False en caso contrario.\n",
    "\n",
    "Esta función es equivalente a `pandas.isna`.\n",
    "\n",
    "Por ejemplo, podemos aplicarla a una serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,np.nan, 7, np.nan, 3])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta funcionalidad tambien esta disponible como método:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos aplicarla a un DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas = pd.DataFrame(\n",
    "                            {\n",
    "                                \"A\": [3, np.nan, 1],\n",
    "                                \"B\": [1, 5, np.nan],\n",
    "                                \"C\": [3, 7, 2],\n",
    "                                \"D\": [np.nan, 2, np.nan]\n",
    "                            },\n",
    "                            index = [\"Ene\", \"Feb\", \"Mar\"]\n",
    ")\n",
    "\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(df_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puede usarse como método:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.2 `pandas.Series.dropna` y `pandas.DataFrame.dropna`\n",
    "\n",
    "El método `dropna` permite, de una forma muy conveniente, filtrar los valores de una estructura de datos pandas para dejar solo aquellos no nulos.\n",
    "\n",
    "Aplicado a una serie, el método `pandas.Series.dropna` devuelve una nueva serie tras eliminar los valores nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,np.nan, 7, np.nan, 3])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicado a un dataframe, el método `pandas.DataFrame.dropna` ofrece algo más de funcionalidad: podemos escoger si queremos eliminar filas o columnas, y si queremos eliminarlas cuando todos sus elementos sean nulos o simplemente cuando alguno de ellos lo sea.  \n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas = pd.DataFrame(\n",
    "                            {\n",
    "                                \"A\": [3, np.nan, 1],\n",
    "                                \"B\": [1, 5, np.nan],\n",
    "                                \"C\": [3, 7, 2],\n",
    "                                \"D\": [np.nan, 2, np.nan]\n",
    "                            },\n",
    "                            index = [\"Ene\", \"Feb\", \"Mar\"]\n",
    ")\n",
    "\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto el método se aplica al eje 0, es decir, se van a eliminar filas que incluyan los valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si especificamos el eje 1, lo que se eliminan son las columnas que incluyan valores nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante el parámetro `how` podemos controlar cómo queremos que se aplique el método: si toma el valor `\"all\"`, solo se eliminarán las filas o columnas en las que todos sus elementos sean nulos. Si toma el valor `\"any\"` (valor por defecto), se eliminarán las filas o columnas en las que algún elemento sea nulo.  \n",
    "De esta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordar que esta función admite el parámetro `inplace=True` para realizar los cambios sobre el mismo DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.3 `pandas.Series.fillna` y `pandas.DataFrame.fillna`  \n",
    "\n",
    "El método `fillna` permite sustituir los valores nulos de una estructura pandas por otro valor según ciertos criterios: pueden sustituirse por un valor concreto o bien puede utilizarse el anterior o posterior valor no nulo (en el caso de los dataframes habrá que especificar el eje sobre el que queremos aplicar la función).\n",
    "\n",
    "Veamos el caso de ejecutar este método en una serie `pandas.Series.fillna`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,np.nan, 7, np.nan, 3])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos indicado el valor 0 como argumento, y es este valor el que se utiliza para sustituir los valores nulos de la serie original.\n",
    "\n",
    "También podríamos haber especificado que el método a utilizar fuese, por ejemplo, el `\"forward fill\"` (`\"ffill\"`), de forma que los valores no nulos se copien \"hacia adelante\" siempre que se encuentren valores nulos.  \n",
    "Esto se indicaría con el parámetro method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.fillna(method = \"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos cómo los valores nulos se han rellenado con el anterior valor no nulo (o, dicho con otras palabras, cómo los valores no nulos se han extendido hacia adelante).\n",
    "\n",
    "Si especificamos el método `\"backward fill\"` (`\"bfill\"`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.fillna(method = \"bfill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...los valores nulos se han rellenado con el siguiente valor no nulo.\n",
    "\n",
    "En el caso de los dataframes (`pandas.DataFrame.fillna`), la funcionalidad es semejante. Como se ha comentado, la mayor diferencia consiste en que, en el caso de querer rellenar los valores nulos con el anterior o posterior no nulo, habrá que indicar el eje del que obtener estos datos. \n",
    "\n",
    "Veamos un ejemplo práctico. Si partimos de este dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas = pd.DataFrame(\n",
    "                            {\n",
    "                                \"A\": [1, 5, 4, 7],\n",
    "                                \"B\": [3, 4, 1, np.nan],\n",
    "                                \"C\": [3, 7, 2, 1],\n",
    "                                \"D\": [np.nan, 2, 2, 3]\n",
    "                            },\n",
    "                            index = [\"Ene\", \"Feb\", \"Mar\", \"Abr\"]\n",
    ")\n",
    "\n",
    "df_ventas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...podemos sustituir los valores nulos por una cifra concreta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si aplicamos el método de `\"forward fill\"` a lo largo del eje 0 (eje por defecto):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.fillna(method = \"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...vemos cómo el primer valor de la columna D no se ha modificado pues no hay ningún valor anterior (en el eje 0) del que tomar el valor.  \n",
    "\n",
    "Y si aplicamos el método \"backward fill\" a lo largo del eje 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.fillna(method = \"bfill\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...vemos que, también en este caso, el valor de la columna D correspondiente a enero no se ha modificado pues, nuevamente, no hay un valor posterior (en el eje 1) del que tomar el valor.\n",
    "\n",
    "En un caso práctico puede resultar recomendable utilizar \"lógica de relleno\" seguida de la asignación de un valor por defecto para los valores nulos que puedan seguir existiendo, para asegurarnos de que todos ellos han sido sustituidos adecuadamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas.fillna(axis = 1, method = \"bfill\").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordar que esta función admite el parámetro `inplace=True` para realizar los cambios sobre el mismo DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.12 Herramientas de visualización\n",
    "\n",
    "Pandas ofrece la funcionalidad de matplotlib a través de un conjunto de funciones y de métodos asociados a los dataframes.\n",
    "\n",
    "Pandas incluye la sublibrería `pandas.plotting` conteniendo herramientas para la visualización de datos multidimensionales.  \n",
    "\n",
    "Vamos a ver las siguientes tres funciones:\n",
    "\n",
    "* scatter_matrix\n",
    "* radviz\n",
    "* parallel_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver como funcinan las visualizaciones, vamos a usar el dataframe df_vinos que hemos cargado previamente desde la bbdd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.1 `pandas.plotting.scatter_matrix`\n",
    "\n",
    "La función `pandas.plotting.scatter_matrix` muestra una matriz de gráficos de dispersión cruzando las características cuantitativas del dataframe indicado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df_vinos, figsize = (10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.2 `pandas.plotting.radviz`\n",
    "\n",
    "El algoritmo RadViz permite proyectar un conjunto de datos multidimensional en un espacio de dos dimensiones y la función `pandas.plotting.radviz` implementa este algoritmo, mostrando una gráfica de dos dimensiones con información del dataframe incluido como argumento.\n",
    "\n",
    "Las características del dataframe son representadas distribuidas uniformemente a lo largo de la circunferencia de un círculo. Cada muestra del dataframe se representa en el interior del círculo de acuerdo con el valor en cada serie según una metáfora física: cada punto se supone unido a cada característica con una fuerza que es proporcional al valor que dicha muestra toma en la serie correspondiente, de forma que la posición final es la posición de equilibrio entre todas las fuerzas que representan las características.\n",
    "\n",
    "Veamos qué resultado ofrece esta función aplicada al dataset df_vinos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 10)\n",
    "pd.plotting.radviz(df_vinos[df_vinos[\"region\"]==\"Rioja\"][[\"type\", \"rating\", \"num_reviews\", \"price\", \"body\", \"acidity\"]], \"type\", ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este gráfico podemos ver que la acidez, el cuerpo y la clasificación representan mejor las caracterísitcas del vino que el número de entrevistas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.3 `pandas.plotting.parallel_coordinates`\n",
    "\n",
    "La función `pandas.plotting.parallel_coordinates` implementa el gráfico de coordenadas paralelas, útil para trazar datos numéricos multivariados y comparar variables y sus relaciones.\n",
    "\n",
    "En estos gráficos, cada característica recibe su propio eje, colocados verticalmente, y las muestras se representan como líneas entre los ejes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos[\"rating2\"] = 100 * df_vinos[\"rating\"]\n",
    "df_vinos[\"price2\"] = df_vinos[\"price\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 10))\n",
    "pd.plotting.parallel_coordinates(df_vinos[df_vinos[\"region\"]==\"Rioja\"][[\"type\", \"rating\", \"price2\"]], \"type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.4 `pandas.DataFrame.plot`\n",
    "\n",
    "El método `pandas.DataFrame.plot` no es más que un envoltorio de la función `matplotlib.pyplot.plot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randn(100).cumsum())\n",
    "s.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluye el parámetro kind que determina el tipo de gráfica a generar (el valor por defecto es \"line\", correspondiente a un gráfico de líneas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos.rating.plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde la versión 0.17 de pandas, cada tipo de gráfica generada para los posibles valores del parámetro kind tienen un método equivalente. De esta forma, df.plot(kind = \"pie\") es equivalente a df.plot.pie()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.5 `plot.bar`\n",
    "\n",
    "El método pandas.DataFrame.plot.bar muestra una gráfica de barras verticales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos.groupby(\"year\", as_index = False).price.mean().plot.bar(\"year\", \"price\", figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2.3.5\n",
    "\n",
    "Haz un gráfico de barras que muestre el rating medio por años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe el código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.6 `plot.barh`\n",
    "\n",
    "El método `pandas.DataFrame.plot.barh` tiene un comportamiento prácticamente idéntico al del método `df.plot.bar` (incluso los parámetros tienen el mismo orden). La única diferencia es que la gráfica de barras resultante se muestra en horizontal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos.groupby(\"year\", as_index = False).price.mean().plot.barh(\"year\", \"price\", figsize=(10, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.7 `plot.line`\n",
    "\n",
    "El método `pandas.DataFrame.plot.line` muestra una gráfica de lineas a partir de los datos contenidos en el dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df_vinos[df_vinos[\"region\"]==\"Rioja\"].groupby(by=[\"year\", \"type\"], as_index = False).price.mean()\n",
    "df_aux = df_aux.pivot_table(values = \"price\", index=df_aux.year, columns = \"type\", aggfunc = \"mean\")\n",
    "df_aux.plot.line(figsize = (20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.8 `plot.hist`\n",
    "\n",
    "El método `pandas.DataFrame.plot.hist` muestra un histograma de los datos que se indique. Este método incluye dos parámetros principales (ambos opcionales): by, que deberá indicar la columna por la que agrupar los datos, y bins, que indicará el número de columnas o bins a crear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos.rating.plot.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.9 `plot.box`\n",
    "\n",
    "El método `pandas.DataFrame.plot.box` crea un diagrama de cajas con los datos indicados. El método incluye un parámetro principal, `by`, que indicará la columna por la que agrupar los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos[df_vinos[\"region\"]==\"Rioja\"][[\"type\", \"rating\", \"price\"]].plot.box(by=\"type\", figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.10 `plot.kde` \n",
    "\n",
    "El método `pandas.DataFrame.plot.kde` genera un gráfico tipo estimación de densidad kernel (KDE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos.rating.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos.price.plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.11 `plot.area`\n",
    "\n",
    "El método `pandas.DataFrame.plot.area` genera un gráfico de áreas. El parámetro stacked (que toma el valor True por defecto) indica si las áreas han de apilarse o no:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos[df_vinos[\"region\"].str.contains(\"Rioja\")].pivot_table(index=\"year\", columns=\"region\", values = \"price\", aggfunc = \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_vinos[df_vinos[\"region\"].str.contains(\"Rioja\")].pivot_table(index=\"year\", columns=\"region\", values = \"price\", aggfunc = \"mean\").plot.area(stacked=False, figsize=(18,10))\n",
    "ax.legend(loc=\"right\", bbox_to_anchor=(1.2,0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.12 `plot.pie`\n",
    "\n",
    "El método `pandas.DataFrame.plot.pie` genera un gráfico circular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos.pivot_table(index=\"region\", values = \"price\", aggfunc = \"sum\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df_vinos.pivot_table(index=\"region\", values = \"num_reviews\", aggfunc = \"sum\").reset_index()\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.pie(df_aux[\"num_reviews\"], labels = df_aux[\"region\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df_vinos[df_vinos[\"region\"].str.contains(\"Rioja\")].pivot_table(index=\"region\", values = \"num_reviews\", aggfunc = \"sum\").reset_index()\n",
    "plt.pie(df_aux[\"num_reviews\"], labels = df_aux[\"region\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer varias representaciones gráficas usando una variable para cada una de ellas. Esto es posible incluyendo en la llamada al método el atributo `subplot=True`.  \n",
    "\n",
    "En el ejemplo siguiente haremos que para cada región en la que se divide la D.O Rioja cree un diagrama de tarta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos[(df_vinos[\"region\"].str.contains(\"Rioja\")) & (df_vinos[\"year\"]>\"2015\")].pivot_table(index = \"year\", columns = \"region\", values = \"num_reviews\", aggfunc = \"sum\").plot.pie(subplots=True, figsize=(20,10), autopct='%1.1f%%', startangle=140, legend = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2.3.6\n",
    "\n",
    "Hacer el mismo gráfico pero esta vez un diagrama de tarta para cada año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos[(df_vinos[\"region\"].str.contains(\"Rioja\")) & (df_vinos[\"year\"]>\"2015\")].pivot_table(index = \"region\", columns = \"year\", values = \"num_reviews\", aggfunc = \"sum\").plot.pie(subplots=True, figsize=(20,10), autopct='%1.1f%%', startangle=140, legend = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.12.13 `plot.scatter`\n",
    "\n",
    "El método `pandas.DataFrame.plot.scatter` crea un diagrama de dispersión de las dos variables involucradas. Además de los parámetros x e y para referenciarlas, incluye el parámetro s que determinará el tamaño de los puntos y el parámetro c, que determinará el color de cada uno de ellos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos.plot.scatter(\"rating\", \"price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisiéramos aplicar un color distinto a cada región, tendríamos que \"mapear\" la columna \"región\" a un conjunto de colores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vinos[(df_vinos[\"region\"].str.contains(\"Rioja\"))].region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colores = {\"Rioja\": \"red\", \"Rioja Alta\": \"blue\", \"Rioja Alavesa\": \"green\"}\n",
    "df_vinos[(df_vinos[\"region\"].str.contains(\"Rioja\"))].plot.scatter(\"rating\", \"price\", c = df_vinos[(df_vinos[\"region\"].str.contains(\"Rioja\"))].region.map(colores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.16 Bibliografía\n",
    "Información de interés de modo de uso de pandas y que ha servido para confeccionar esta documentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sitio oficial de pandas](https://pandas.pydata.org/)  \n",
    "[API de pandas](https://pandas.pydata.org/docs/reference/index.html#api)  \n",
    "[Aprende pandas con Alf](https://aprendeconalf.es/docencia/python/manual/pandas/)  \n",
    "[Interactive Chaos](https://interactivechaos.com/es/manual/tutorial-de-pandas/presentacion)  \n",
    "[Kaggle](https://www.kaggle.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
